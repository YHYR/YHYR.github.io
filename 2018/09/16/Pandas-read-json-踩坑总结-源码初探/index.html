<!DOCTYPE html PUBLIC "-//WAPFORUM//DTD XHTML Mobile 1.0//EN" "http://www.wapforum.org/DTD/xhtml-mobile10.dtd">
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=yes">
  
  
  <title>  Pandas.read_json()踩坑总结 &amp; 源码初探 |   【永恒依然】的博客 </title>

 
  
    <link rel="icon" href="/images/favicon.png">
  


  <link rel="stylesheet" href="/nayo.min.css"> 
</head>  
  <body>   
    
      <header class="header">
	
  <nav class="header-nav">        
   
    <span class="iconfont icon-menu mobile-toggle"></span>   	

    <!-- <a class="header-logo" href="/"></a> -->

    <div class="header-menu">          
              
            

              <a class="header-menu-link" id="header-menu-home" href="/">Home</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-archives" href="/archives">Archives</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-tags" href="/tags">Tags</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-about" href="/about">About</a>     

            
            
            

              <a class="iconfont icon-menu-search header-menu-link" id="header-menu-search"></a>

            
                
    </div>  
    
  </nav>
</header>   

      <div class="container">       
          
          
            <section class="main">  
          

          <article class="post">
  
	<div class="post-header">

	<p class="post-title">	
		Pandas.read_json()踩坑总结 &amp; 源码初探
	</p>
			

	<div class="meta-info">	
	<span>
		Sep 16, 2018
	</span>

	
	
		<i class="iconfont icon-words"></i>
		<span>
			9112
		</span>
	
</div>

</div> 
	 

	  <div class="post-content slideDownMin">

		

			
					<p>　　基于实际工作中遇到的一种极端场景来分析Pandas.read_json()方法的源码实现；顺便站在个人学习和使用的角度出发，吐槽一下该方法底层设计的不合理之处。</p>
<a id="more"></a>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>环境依赖：Python 2.7</p>
<p>样例数据(json文件)</p>
<p><img src="./样例数据.png" alt="样例数据"></p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>　　通过Pandas.read_json(jsonFilePath)方法读取json文件时，会出现数据内容发生奇怪的转变；Eg：假设样例数据的文件名为data.json，则执行pd.read_json(data.json)后的结果以及各列数据的数据类型分别如下图所示：</p>
<p><img src="./read_json解析结果.png" alt="read_json解析结果"></p>
<p><img src="./read_json结果数据类型.png" alt="read_json结果数据类型"></p>
<p>　　相较于原始数据集，经过该方法执行后的结果有两处不一致的地方：第一，userId和telephone这两列的数据类型由原本的String变成了int64；第二，<font color="red">userId字段的值发生了变化</font>。</p>
<h2 id="源码剖析"><a href="#源码剖析" class="headerlink" title="源码剖析"></a>源码剖析</h2><p>接下来将从深入源码来探究这种情况发生的原因；pd.read_json()的源码及其该方法之间的调用时序分别如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_json</span><span class="params">(path_or_buf=None, orient=None, typ=<span class="string">'frame'</span>, dtype=True,</span></span></span><br><span class="line"><span class="function"><span class="params">              convert_axes=True, convert_dates=True, keep_default_dates=True,</span></span></span><br><span class="line"><span class="function"><span class="params">              numpy=False, precise_float=False, date_unit=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Convert a JSON string to pandas object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    path_or_buf : a valid JSON string or file-like, default: None</span></span><br><span class="line"><span class="string">        The string could be a URL. Valid URL schemes include http, ftp, s3, and</span></span><br><span class="line"><span class="string">        file. For file URLs, a host is expected. For instance, a local file</span></span><br><span class="line"><span class="string">        could be ``file://localhost/path/to/table.json``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    orient</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * `Series`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - default is ``'index'``</span></span><br><span class="line"><span class="string">          - allowed values are: ``&#123;'split','records','index'&#125;``</span></span><br><span class="line"><span class="string">          - The Series index must be unique for orient ``'index'``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * `DataFrame`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - default is ``'columns'``</span></span><br><span class="line"><span class="string">          - allowed values are: &#123;'split','records','index','columns','values'&#125;</span></span><br><span class="line"><span class="string">          - The DataFrame index must be unique for orients 'index' and</span></span><br><span class="line"><span class="string">            'columns'.</span></span><br><span class="line"><span class="string">          - The DataFrame columns must be unique for orients 'index',</span></span><br><span class="line"><span class="string">            'columns', and 'records'.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * The format of the JSON string</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - split : dict like</span></span><br><span class="line"><span class="string">            ``&#123;index -&gt; [index], columns -&gt; [columns], data -&gt; [values]&#125;``</span></span><br><span class="line"><span class="string">          - records : list like</span></span><br><span class="line"><span class="string">            ``[&#123;column -&gt; value&#125;, ... , &#123;column -&gt; value&#125;]``</span></span><br><span class="line"><span class="string">          - index : dict like ``&#123;index -&gt; &#123;column -&gt; value&#125;&#125;``</span></span><br><span class="line"><span class="string">          - columns : dict like ``&#123;column -&gt; &#123;index -&gt; value&#125;&#125;``</span></span><br><span class="line"><span class="string">          - values : just the values array</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    typ : type of object to recover (series or frame), default 'frame'</span></span><br><span class="line"><span class="string">    dtype : boolean or dict, default True</span></span><br><span class="line"><span class="string">        If True, infer dtypes, if a dict of column to dtype, then use those,</span></span><br><span class="line"><span class="string">        if False, then don't infer dtypes at all, applies only to the data.</span></span><br><span class="line"><span class="string">    convert_axes : boolean, default True</span></span><br><span class="line"><span class="string">        Try to convert the axes to the proper dtypes.</span></span><br><span class="line"><span class="string">    convert_dates : boolean, default True</span></span><br><span class="line"><span class="string">        List of columns to parse for dates; If True, then try to parse</span></span><br><span class="line"><span class="string">        datelike columns default is True; a column label is datelike if</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it ends with ``'_at'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it ends with ``'_time'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it begins with ``'timestamp'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it is ``'modified'``, or</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it is ``'date'``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    keep_default_dates : boolean, default True</span></span><br><span class="line"><span class="string">        If parsing dates, then parse the default datelike columns</span></span><br><span class="line"><span class="string">    numpy : boolean, default False</span></span><br><span class="line"><span class="string">        Direct decoding to numpy arrays. Supports numeric data only, but</span></span><br><span class="line"><span class="string">        non-numeric column and index labels are supported. Note also that the</span></span><br><span class="line"><span class="string">        JSON ordering MUST be the same for each term if numpy=True.</span></span><br><span class="line"><span class="string">    precise_float : boolean, default False</span></span><br><span class="line"><span class="string">        Set to enable usage of higher precision (strtod) function when</span></span><br><span class="line"><span class="string">        decoding string to double values. Default (False) is to use fast but</span></span><br><span class="line"><span class="string">        less precise builtin functionality</span></span><br><span class="line"><span class="string">    date_unit : string, default None</span></span><br><span class="line"><span class="string">        The timestamp unit to detect if converting dates. The default behaviour</span></span><br><span class="line"><span class="string">        is to try and detect the correct precision, but if this is not desired</span></span><br><span class="line"><span class="string">        then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,</span></span><br><span class="line"><span class="string">        milliseconds, microseconds or nanoseconds respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    result : Series or DataFrame</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    filepath_or_buffer, _, _ = get_filepath_or_buffer(path_or_buf)</span><br><span class="line">    <span class="keyword">if</span> isinstance(filepath_or_buffer, compat.string_types):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            exists = os.path.exists(filepath_or_buffer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if the filepath is too long will raise here</span></span><br><span class="line">        <span class="comment"># 5874</span></span><br><span class="line">        <span class="keyword">except</span> (TypeError, ValueError):</span><br><span class="line">            exists = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists:</span><br><span class="line">            <span class="keyword">with</span> open(filepath_or_buffer, <span class="string">'r'</span>) <span class="keyword">as</span> fh:</span><br><span class="line">                json = fh.read()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            json = filepath_or_buffer</span><br><span class="line">    <span class="keyword">elif</span> hasattr(filepath_or_buffer, <span class="string">'read'</span>):</span><br><span class="line">        json = filepath_or_buffer.read()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        json = filepath_or_buffer</span><br><span class="line"></span><br><span class="line">    obj = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">'frame'</span>:</span><br><span class="line">        obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,</span><br><span class="line">                          keep_default_dates, numpy, precise_float,</span><br><span class="line">                          date_unit).parse()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">'series'</span> <span class="keyword">or</span> obj <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(dtype, bool):</span><br><span class="line">            dtype = dict(data=dtype)</span><br><span class="line">        obj = SeriesParser(json, orient, dtype, convert_axes, convert_dates,</span><br><span class="line">                           keep_default_dates, numpy, precise_float,</span><br><span class="line">                           date_unit).parse()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> obj</span><br></pre></td></tr></table></figure>
<p><img src="./readJson方法间调用时序.png" alt="read_json方法间调用时序"></p>
<p>　　通过这段源码可以看出，read_json方法主要做了三件事：首先基于给定的参数做校验，然后获取指定url或流中的数据信息转化为jsonStr，最后一步对该jsonStr进行解析。用户可显示的通过typ字段来指定解析结果的类型(DataFrame or Series)。解析逻辑所对应的对象模型如下所示：</p>
<p><img src="./Parse对象模型.png" alt="Parse对象模型"></p>
<p>　　由于Series的解析逻辑比较简单，且实际工作中直接基于DataFrame的操作比较多，因此这里主要对jsonStr解析成DataFrame的过程做进一步的梳理。在第三步数据解析的过程中，<code>FrameParser.parse()</code>方法的本质其实是调用了父类Parse的parse方法，该方法的职能有三个：首先将jsonStr解析成DataFrame数据结构；其次对解析结果的轴做数据类型转化；最后<font color="red">尝试对数据进行类型转化</font>。源码及对应的方法间调用时序如下图所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># try numpy</span></span><br><span class="line">      numpy = self.numpy</span><br><span class="line">      <span class="keyword">if</span> numpy:</span><br><span class="line">          self._parse_numpy()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          self._parse_no_numpy()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.obj <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">      <span class="keyword">if</span> self.convert_axes:</span><br><span class="line">          self._convert_axes()</span><br><span class="line">      self._try_convert_types()</span><br><span class="line">      <span class="keyword">return</span> self.obj</span><br></pre></td></tr></table></figure>
<p><img src="/images/placeholder.png" alt="Parse.parse方法间调用时序" data-src="./Parse.parse方法间调用时序.png" class="lazyload"></p>
<p>　　在解析jsonStr时，首先会根据参数numpy来判断是否需要将数据反序列化为numpy数组类型；这个反序列化的过程是通过Pandas内部封装的json工具类的loads方法来实现的；然后将反序列化后的Dict对象经过DataFrame类进行数据初始化，从而得到该jsonFile所对应的DataFrame数据结构。由于<code>_parse_no_numpy()</code> 和<code>_parse_numpy()</code>这两个方法的原理类似，这里以<code>FrameParse._parse_numpy()</code>为例，看一下对应的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_parse_numpy</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">    json = self.json</span><br><span class="line">    orient = self.orient</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> orient == <span class="string">"columns"</span>:</span><br><span class="line">        args = loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>, labelled=<span class="keyword">True</span>,</span><br><span class="line">                     precise_float=self.precise_float)</span><br><span class="line">        <span class="keyword">if</span> args:</span><br><span class="line">            args = (args[<span class="number">0</span>].T, args[<span class="number">2</span>], args[<span class="number">1</span>])</span><br><span class="line">        self.obj = DataFrame(*args)</span><br><span class="line">    <span class="keyword">elif</span> orient == <span class="string">"split"</span>:</span><br><span class="line">        decoded = loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                        precise_float=self.precise_float)</span><br><span class="line">        decoded = dict((str(k), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> compat.iteritems(decoded))</span><br><span class="line">        self.check_keys_split(decoded)</span><br><span class="line">        self.obj = DataFrame(**decoded)</span><br><span class="line">    <span class="keyword">elif</span> orient == <span class="string">"values"</span>:</span><br><span class="line">        self.obj = DataFrame(loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                                   precise_float=self.precise_float))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.obj = DataFrame(*loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                                    labelled=<span class="keyword">True</span>,</span><br><span class="line">                                    precise_float=self.precise_float))</span><br></pre></td></tr></table></figure>
<p>　　<strong>注意这里的写法</strong>：父类Parse中是没有<code>_parse_no_numpy()</code> 和<code>_parse_numpy()</code>这两个方法的，也就是说是在父类调用子类的方法。其实不同于Java这类编程语言，在Python中需要从对象生成的角度来看待这个问题；因为此时的Parse类就是FrameParser，所以<code>self._parse_no_numpy()</code>的调用本质就是其实现类自身的方法，所以就有了这种看似奇怪的父调子写法。</p>
<p>　　当执行完数据解析后，我们已经得到DataFrame，那么先别着急往下看，在Debug下看看此时解析出来的结果如何：</p>
<p><img src="/images/placeholder.png" alt="parse解析结果" data-src="./parse解析结果.png" class="lazyload"></p>
<p><img src="/images/placeholder.png" alt="parse解析字段类型" data-src="./parse解析字段类型.png" class="lazyload"></p>
<p>　　对比发现，走到这一步时解析结果和字段类型都和我们原始的数据集保持一致，所以可以肯定数据的解析逻辑是没有问题的，那么跟着源码继续往下走，就来到frame轴类型转化的过程；截止目前个人还是不太明白这层处理的意义是什么；因为在对index和column进行数据类型转化时，index列的类型是int64，而column的名字也都是字符串从而导致尝试类型转化无效。所以对于这处有了解的环境补充和指教。因为这次的逻辑判断可通过显示的控制，且经过测试后发现执行对结果并无影响，因此在这里不做过多的讨论。</p>
<p>　　最后来看看parse的最后一个职能：尝试对数据进行类型转化。该方法在父类的实现只是简单的异常捕获，具体的处理逻辑在对应的子类中实现，在这里看一下FrameParser类中方法<code>_try_convert_types()</code>的源码实现和对应的方法间调用时序：</p>
<p><img src="/images/placeholder.png" alt="FrameParse._try_convert_types源码.png" data-src="./FrameParse._try_convert_types源码.png" class="lazyload"></p>
<p><img src="/images/placeholder.png" alt="try_convert_types时序" data-src="./try_convert_types时序.png" class="lazyload"></p>
<p>　　在FrameParse中，会对数据进行两次转化尝试：首先会尝试进行日期类型的转化，其次会对数据进行数值类型转化。在日期类型的尝试转化中，是基于特殊命名的列数据进行处理，具体包括列名以“_at”，“_time”结尾、或者以“timestamp”开头或者列名等于“modified”，“date”， “datetime”。因为这种处理对最终结果不会产生影响，所以在这里不做过多讨论。</p>
<p>　　跳过日期类型转化后，就来到最后一步，数据的数值类型转化尝试。方法<code>_process_converter()</code>可以抽象的理解为一个数据转化工具类，负责对数据集中的每一列数据按照指定的转化规则进行转化尝试；该方法的第一个参数类型是一个方法，作用就是指定需要对数据列做哪种转化。在这里传入父类的<code>Parse._try_convert_data()</code>方法，该方法的作用就是尝试将数据转化成数值类型；该方法的源码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_try_convert_data</span><span class="params">(self, name, data, use_dtypes=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                      convert_dates=True)</span>:</span></span><br><span class="line">    <span class="string">""" try to parse a ndarray like into a column by inferring dtype """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># don't try to coerce, unless a force conversion</span></span><br><span class="line">    <span class="keyword">if</span> use_dtypes:</span><br><span class="line">        <span class="keyword">if</span> self.dtype <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">            <span class="keyword">return</span> data, <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">elif</span> self.dtype <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># dtype to force</span></span><br><span class="line">            dtype = (self.dtype.get(name)</span><br><span class="line">                     <span class="keyword">if</span> isinstance(self.dtype, dict) <span class="keyword">else</span> self.dtype)</span><br><span class="line">            <span class="keyword">if</span> dtype <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    dtype = np.dtype(dtype)</span><br><span class="line">                    <span class="keyword">return</span> data.astype(dtype), <span class="keyword">True</span></span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">return</span> data, <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> convert_dates:</span><br><span class="line">        new_data, result = self._try_convert_to_date(data)</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">            <span class="keyword">return</span> new_data, <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    result = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data.dtype == <span class="string">'object'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># try float</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = data.astype(<span class="string">'float64'</span>)</span><br><span class="line">            result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data.dtype.kind == <span class="string">'f'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> data.dtype != <span class="string">'float64'</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># coerce floats to 64</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                data = data.astype(<span class="string">'float64'</span>)</span><br><span class="line">                result = <span class="keyword">True</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># do't coerce 0-len data</span></span><br><span class="line">    <span class="keyword">if</span> len(data) <span class="keyword">and</span> (data.dtype == <span class="string">'float'</span> <span class="keyword">or</span> data.dtype == <span class="string">'object'</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># coerce ints if we can</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            new_data = data.astype(<span class="string">'int64'</span>)</span><br><span class="line">            <span class="keyword">if</span> (new_data == data).all():</span><br><span class="line">                data = new_data</span><br><span class="line">                result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># coerce ints to 64</span></span><br><span class="line">    <span class="keyword">if</span> data.dtype == <span class="string">'int'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># coerce floats to 64</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = data.astype(<span class="string">'int64'</span>)</span><br><span class="line">            result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data, result</span><br></pre></td></tr></table></figure>
<p>　　回顾一下文章一开始提到的例子，具体的调用方法为<code>pd.read_json(filePath)</code>，则通过查看源码的参数注解可知dtype默认为True，此时在方法<code>_try_convert_data</code>里，由于user_dtypes和dtype同为True，convert_dates为False，所以代码直接跳过前面的逻辑判断和时间类型转化尝试，直接进入数值类型的转化尝试中，读完源码就可以看到数据会先尝试转化成float64类型，然后尝试转化为int64类型。通过一步步的Debug，也终于找到问题发生的根源：当代码经过如下位置时，查看一下此时对应的数据结果，如下图所示：</p>
<p><img src="/images/placeholder.png" alt="str转float上溢" data-src="./str转float上溢.png" class="lazyload"></p>
<p>　　看到这也就真想大白了：基于<code>pd.read_json(path)</code>这种写法，底层会对每列数据进行数值类型转化尝试；又因为原始数据集中的userId是数值类型的字符串，所以在将Object转为float64时不会报错，从而再经过后面的int类型的转化，从而导致我们的最终看到的数据类型发生变化。我们可以看到telephone的类型发生了变化，但是数据类型缺没有发生改变，而userId的内容都发生的奇怪的变化，这个原因又是什么呢？</p>
<p>　　其实这个问题的本质和Python和Pandas就没太大关系了，要弄清这个原因，就需要从计算机存储浮点数的机制说起。因为Python的float类型是存在IEEE 745标准，因此这里的float64即就是双精度浮点数，所以在内存中，每个双精度浮点数所占用的总位数为64位，符号位占1位，阶数占11位，尾数占52位，那么：2<sup>52</sup>=4503599627370496，即双精度浮点数的有效位数为16位。由于userId是一个19位的字符串，所以在做类型转化的时候会因为浮点数上溢现象导致数据失真；这就是为什么经过<code>astype(&#39;float64&#39;)</code>后数据内容发生变化的原因。</p>
<p>　　既然在实际应用中，无法保证、要求或者约束原始数据集，那么如果规避这种因为浮点数上溢带来的数据失真的情况呢？我们再来看一下那个数据类型转化的方法<code>_try_converty_data()</code>的源码：</p>
<p><img src="/images/placeholder.png" alt="try_convert_data源码_解析判断" data-src="./try_convert_data源码_解析判断.png" class="lazyload"></p>
<p>　　通过阅读上下文的代码可知，user_dtyps恒为True，但是dtype可以让用户显示的指定，只是如果不指定默认为True，从而导致浮点数存储上溢的情况；当再次看到这里的判断逻辑不难发现，如果把dtype设置为False，则可以完全避免数据类型尝试转化的过程，从而可以保证数据的真实性和有效性；与此同时，通过查阅<code>pd.read_josn()</code>的参数注解可知道，dtype可以为Boolean型，同样也可以为Dict类型，结合源码可以发现可以自定义指定需要转化的数据列和数据类型；这样我们也可以通过显示的指定userId的转化类型来规避这种上溢带来的问题。上述两种方法都是有效的，在这里我以第二种为例，重修修改一下代码：</p>
<p><img src="/images/placeholder.png" alt="read_json自定义dtype" data-src="./read_json自定义dtype.png" class="lazyload"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>　　在基于pandas处理数据时，尤其是通过读取外部数据源来做分析时，一定要注意数据类型的转化问题，避免出现类似这种因为底层数据存储溢出导致数据失真、或者数据类型变化导致的错误【Eg：pd.read_json()，pd.read_csv()】。</p>
<p>　　最后在顺便吐槽一下，pandas底层的这个设定也太过于奇葩；应该将read_json()方法中的参数dtype的默认值设置为False，让用户去显示的做类型转化；而不应该为了凸显在数据处理上的便利性，去容忍这种这种数据溢出的潜在Bug(亦或是pandas的开发者压根没意识到这个问题 ~~~ 哈哈 ^v^)。</p>
  	
					
	  </div>     
	  

	
<div class="post-meta">
      	

      
        <i class="iconfont icon-tag"></i>     
          <a class="tag-link" href="/tags/Python/">Python</a> <a class="tag-link" href="/tags/数据分析/">数据分析</a>    
      	
</div>





<div class="post-footer">
  <div class="pf-left">
      <img class="pf-avatar lazyload" src="/images/placeholder.png" data-src="/images/header.jpg">
      <p class="pf-des">YHYR</p>
  </div>

  <div class="pf-right">           
      <div class="pf-links">
        




<span class="donate-btn">
	<span class="iconfont icon-donate"></span>
</span>


<div id="donate-box" class="sildeUpMin">

	<span class="donate-cancel iconfont icon-cancel"></span>

	<div class="donate-img-box">
		<img id="donate-qr-wechat" class="noLazyLoad donate-img lazyload" src="/images/placeholder.png" alt="No Donate Image!" data-src="/images/donate_wechat.png">	
		<img id="donate-qr-alipay" class="noLazyLoad donate-img lazyload" src="/images/placeholder.png" alt="No Donate Image!" data-src="/images/donate_wechat.png">	
	</div>

	<span class="donate-word">您的认可是我坚持下去的理由</span>

	<div class="donate-list">
		<span class="iconfont icon-donate-wechat"></span>
		<span class="iconfont icon-donate-alipay"></span>
	</div>

</div>

 
        
	
<script id="-mob-share" src="http://f1.webshare.mob.com/code/mob-share.js?appkey=21d601593a1de"></script>
	
	<span class="share-btn">
	<span class="iconfont icon-share"></span>
	</span>


	<div class="-mob-share sildeUpMin">
		   			             
            <a class="iconfont  icon-share-qq -mob-share-qq"></a>		
     	   			             
            <a class="iconfont  icon-share-weixin -mob-share-weixin"></a>		
     	   			             
            <a class="iconfont  icon-share-weibo -mob-share-weibo"></a>		
     	   			             
            <a class="iconfont  icon-share-douban -mob-share-douban"></a>		
     	   			             
            <a class="iconfont  icon-share-facebook -mob-share-facebook"></a>		
     	   			             
            <a class="iconfont  icon-share-twitter -mob-share-twitter"></a>		
     	   			             
            <a class="iconfont  icon-share-google -mob-share-google"></a>		
     	   
	</div>	

      </div>  
    <nav class="pf-paginator">
      
         
          <a href="/2018/10/28/基于网易云音乐的分布式爬虫实现/" data-hover="基于网易云音乐的分布式爬虫实现">Prev</a>      
            
        
      
        
        <a href="/2018/07/03/基于centOS-7搭建FTP服务器/" data-hover="基于centOS 7搭建FTP服务器"> Next</a>
            
  </nav>   
  </div>
</div> 
	


    
    <div id="disqus_thread"></div>

    <script>
    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://'+'lemonreds'+'.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());    
    (d.head || d.body).appendChild(s);
    })();
    </script>

    <noscript>Please enable JavaScript to view the  <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>


	
</article>

          </section> 
      </div>            
    
    <a id="backTop">
      <span>
        <i class="iconfont icon-backtotop"></i>
      </span>
    </a> 

  
    

        
        <div class="search-container sildeUpMin">


            <div class="search-header">
            <input type="text" placeholder="Typing Something here." id="search-input" class="search-input">  
            <span class="search-cancel iconfont icon-cancel"></span>
          
            </div>
              
            <div id="search-result" class="search-result"></div>

        </div>
 

     <div class="mobile-menu">      

      
      <img class="mobile-menu-icon lazyload" src="/images/placeholder.png" data-src="/images/favicon.png">   
      

         
            

            <a class="mobile-menu-link" href="/">Home
            </a>
            
         
            

            <a class="mobile-menu-link" href="/archives">Archives
            </a>
            
         
            

            <a class="mobile-menu-link" href="/tags">Tags
            </a>
            
         
            

            <a class="mobile-menu-link" href="/about">About
            </a>
            
         
                          

            <a class="mobile-menu-link mobile-menu-search" href="#">Search </a>                 
            
         
      
</div>        
    


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?636802045446222199ae541e32c8133e"; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>





     
    




<footer id="footer">	    

		
		<div class="footer-copyright">
		&copy;
		
		2018		
		
		YHYR
		<br>
		<!-- annotate theme msg in footer  by yhyr 2018/06/02
		Theme By
		<a href="https://github.com/Lemonreds/hexo-theme-Nayo" target="_blank">Nayo</a>	
		-->
		</div>			
	 
</footer>   

  

    <script src="/nayo.bundle.js"></script>           
  </body>        
</html>