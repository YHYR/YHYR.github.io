<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>基于网易云音乐的分布式爬虫实现</title>
      <link href="/2018/10/28/%E5%9F%BA%E4%BA%8E%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0/"/>
      <content type="html"><![CDATA[<p>通过scrapy-redis + HDFS 实现网易云音乐的用户、评论数据的爬取和持久化。源代码详见<a href="https://github.com/YHYR/CloudMusicSpider" target="_blank" rel="noopener">Github</a></p><a id="more"></a><p><em>注：此爬虫项目及其数据仅作学术学习使用</em></p><h1 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h1><h4 id="Python-版本"><a href="#Python-版本" class="headerlink" title="Python 版本"></a>Python 版本</h4><blockquote><p>Python 3.6.5</p></blockquote><h4 id="依赖包"><a href="#依赖包" class="headerlink" title="依赖包"></a>依赖包</h4><blockquote><p>scrapy_redis</p><p>redis</p><p>mysql-python</p><p>kafka-python</p><p>hdfs</p></blockquote><h3 id="数据API接口"><a href="#数据API接口" class="headerlink" title="数据API接口"></a>数据API接口</h3><blockquote><p>详见<a href="https://github.com/YHYR/CloudMusicSpider" target="_blank" rel="noopener">Github</a></p></blockquote><h1 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h1><h3 id="数据依赖关系"><a href="#数据依赖关系" class="headerlink" title="数据依赖关系"></a>数据依赖关系</h3><p><img src="./数据关系.png" alt="数据关系"></p><h3 id="时序"><a href="#时序" class="headerlink" title="时序"></a>时序</h3><p><img src="./爬虫时序.png" alt="爬虫时序"></p><p>　　上图详细说明了整个爬虫工程的前一半的数据抽取逻辑；关于用户类数据的抽取在实现逻辑上与上图基本一致。在用户相关数据的爬取上，实现了在尽可能多的爬取用户数据的同时，有效规避重复爬取。实现逻辑如下：</p><p>　　<strong>在代码实现层面上，显示的指定用户相关数据的爬取逻辑</strong>。优先级为：用户基本信息 &gt; 用户粉丝信息 = 用户关注信息 = 用户听歌记录。即就是只有在爬取到一个用户的基本信息以后，才初始化这个用户的附属信息的URL(例：粉丝列表、关注列表、听歌记录)。这样就可以保证只要爬取用户基本信息时不重复，则附属属性数据的爬取就不会重复。所以在Redis中单独维护一个用户UserId的数据集，每当爬取歌曲的评论数据、用户的粉丝或者关注者数据时，都会先校验当前用户是否在该数据集内；如果不在则初始化用户的基本信息URL到请求队列中，反之则认为该用户已经爬取过。</p><p>　　为了提升用户数据量，在收集歌曲评论中所涉及到的用户信息的同时，深度爬取每个用户所对应的关注和粉丝列表的信息。</p><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><p>　　这里选择将爬取到的数据持久化到HDFS中，便于单机自测；如果想真正的基于多机器实现分布式爬取数据，建议将数据改写到Kafka中；因为HDFS的特性为一次写，多次读；且不支持在统一文件的任意offset进行写操作；因此对于HDFS文件的操作只有append，且不支持并发写操作。如果提升爬虫效率，建议将数据先写入Ｋafka，然后通过后台脚本通过多线程/多进程进行消费和持久化操作。</p><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>　由于我们的数据链路存在一定的依赖关系，但也并非是单线程的地步。所以在具体实现时采用scrapy-redis框架来实现分布式的效果。在请求队列上，可以为每一个Spider在Redis中开辟一个Request队列，这样有效的提升爬取效率。当然要想持续爬取，加代理也是必不可少的。有关<font color="red">免费代理IP的爬取和有效性校验</font>的实现，可详见<a href="https://github.com/YHYR/ProxyIpSpider" target="_blank" rel="noopener">Github</a>。</p><p>需要注意的是，scrapy-redis不支持在请求队列中实现去重。源码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisMixin</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Mixin class to implement reading urls from a redis queue."""</span></span><br><span class="line">    redis_key = <span class="keyword">None</span></span><br><span class="line">    redis_batch_size = <span class="keyword">None</span></span><br><span class="line">    redis_encoding = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Redis client placeholder.</span></span><br><span class="line">    server = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Returns a batch of start requests from redis."""</span></span><br><span class="line">        <span class="keyword">return</span> self.next_requests()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_redis</span><span class="params">(self, crawler=None)</span>:</span></span><br><span class="line">        <span class="string">"""Setup redis connection and idle signal.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        This should be called after the spider has set its crawler object.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.server <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># We allow optional crawler argument to keep backwards</span></span><br><span class="line">            <span class="comment"># compatibility.</span></span><br><span class="line">            <span class="comment"># <span class="doctag">XXX:</span> Raise a deprecation warning.</span></span><br><span class="line">            crawler = getattr(self, <span class="string">'crawler'</span>, <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"crawler is required"</span>)</span><br><span class="line"></span><br><span class="line">        settings = crawler.settings</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.redis_key <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.redis_key = settings.get(</span><br><span class="line">                <span class="string">'REDIS_START_URLS_KEY'</span>, defaults.START_URLS_KEY,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.redis_key = self.redis_key % &#123;<span class="string">'name'</span>: self.name&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.redis_key.strip():</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_key must not be empty"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.redis_batch_size <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Deprecate this setting (REDIS_START_URLS_BATCH_SIZE).</span></span><br><span class="line">            self.redis_batch_size = settings.getint(</span><br><span class="line">                <span class="string">'REDIS_START_URLS_BATCH_SIZE'</span>,</span><br><span class="line">                settings.getint(<span class="string">'CONCURRENT_REQUESTS'</span>),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.redis_batch_size = int(self.redis_batch_size)</span><br><span class="line">        <span class="keyword">except</span> (TypeError, ValueError):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_batch_size must be an integer"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.redis_encoding <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.redis_encoding = settings.get(<span class="string">'REDIS_ENCODING'</span>, defaults.REDIS_ENCODING)</span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">"Reading start URLs from redis key '%(redis_key)s' "</span></span><br><span class="line">                         <span class="string">"(batch size: %(redis_batch_size)s, encoding: %(redis_encoding)s"</span>,</span><br><span class="line">                         self.__dict__)</span><br><span class="line"></span><br><span class="line">        self.server = connection.from_settings(crawler.settings)</span><br><span class="line">        <span class="comment"># The idle signal is called when the spider has no requests left,</span></span><br><span class="line">        <span class="comment"># that's when we will schedule new requests from redis queue</span></span><br><span class="line">        crawler.signals.connect(self.spider_idle, signal=signals.spider_idle)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Returns a request to be scheduled or none."""</span></span><br><span class="line">        use_set = self.settings.getbool(<span class="string">'REDIS_START_URLS_AS_SET'</span>, defaults.START_URLS_AS_SET)</span><br><span class="line">        fetch_one = self.server.spop <span class="keyword">if</span> use_set <span class="keyword">else</span> self.server.lpop</span><br><span class="line">        <span class="comment"># <span class="doctag">XXX:</span> Do we need to use a timeout here?</span></span><br><span class="line">        found = <span class="number">0</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> Use redis pipeline execution.</span></span><br><span class="line">        <span class="keyword">while</span> found &lt; self.redis_batch_size:</span><br><span class="line">            data = fetch_one(self.redis_key)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">                <span class="comment"># Queue empty.</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            req = self.make_request_from_data(data)</span><br><span class="line">            <span class="keyword">if</span> req:</span><br><span class="line">                <span class="keyword">yield</span> req</span><br><span class="line">                found += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.logger.debug(<span class="string">"Request not made from data: %r"</span>, data)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> found:</span><br><span class="line">            self.logger.debug(<span class="string">"Read %s requests from '%s'"</span>, found, self.redis_key)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_request_from_data</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="string">"""Returns a Request instance from data coming from Redis.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        By default, ``data`` is an encoded URL. You can override this method to</span></span><br><span class="line"><span class="string">        provide your own message decoding.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        data : bytes</span></span><br><span class="line"><span class="string">            Message from redis.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        url = bytes_to_str(data, self.redis_encoding)</span><br><span class="line">        <span class="keyword">return</span> self.make_requests_from_url(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">schedule_next_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Schedules a request if available"""</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> While there is capacity, schedule a batch of redis requests.</span></span><br><span class="line">        <span class="keyword">for</span> req <span class="keyword">in</span> self.next_requests():</span><br><span class="line">            self.crawler.engine.crawl(req, spider=self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_idle</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Schedules a request if available, otherwise waits."""</span></span><br><span class="line">        <span class="comment"># <span class="doctag">XXX:</span> Handle a sentinel to close the spider.</span></span><br><span class="line">        self.schedule_next_requests()</span><br><span class="line">        <span class="keyword">raise</span> DontCloseSpider</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisCrawlSpider</span><span class="params">(RedisMixin, CrawlSpider)</span>:</span></span><br><span class="line">    <span class="string">"""Spider that reads urls from redis queue when idle.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    redis_key : str (default: REDIS_START_URLS_KEY)</span></span><br><span class="line"><span class="string">        Redis key where to fetch start URLs from..</span></span><br><span class="line"><span class="string">    redis_batch_size : int (default: CONCURRENT_REQUESTS)</span></span><br><span class="line"><span class="string">        Number of messages to fetch from redis on each attempt.</span></span><br><span class="line"><span class="string">    redis_encoding : str (default: REDIS_ENCODING)</span></span><br><span class="line"><span class="string">        Encoding to use when decoding messages from redis queue.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Settings</span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string">    REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls")</span></span><br><span class="line"><span class="string">        Default Redis key where to fetch start URLs from..</span></span><br><span class="line"><span class="string">    REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS)</span></span><br><span class="line"><span class="string">        Default number of messages to fetch from redis on each attempt.</span></span><br><span class="line"><span class="string">    REDIS_START_URLS_AS_SET : bool (default: True)</span></span><br><span class="line"><span class="string">        Use SET operations to retrieve messages from the redis queue.</span></span><br><span class="line"><span class="string">    REDIS_ENCODING : str (default: "utf-8")</span></span><br><span class="line"><span class="string">        Default encoding to use when decoding messages from redis queue.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(self, crawler, *args, **kwargs)</span>:</span></span><br><span class="line">        obj = super(RedisCrawlSpider, self).from_crawler(crawler, *args, **kwargs)</span><br><span class="line">        obj.setup_redis(crawler)</span><br><span class="line">        <span class="keyword">return</span> obj</span><br></pre></td></tr></table></figure><p>　　当启动一个Spider后，就会读取Redis中指定key下的url信息。如果当前key下没有相应的value就等待；当有值时，则会调用<code>next_requests</code>方法来获取数据；查看方法next_requests的源码不难看出，<strong>无论你当前的key的数据类型是什么，最终都会pop掉</strong>，从而导致Redis中不在有这个值。这也就是上述中提到的为什么要自己通过维护userId数据集来实现抽取的唯一性，而不是用这个请求队列作为唯一性校验的原因。对于一个正常的设计，应该是在项目运行一段时间后会出现所有的Spider都处于挂起等待的状态，此时所涉及到的所有请求队列应该均为空；否则就有可能因为设计问题导致无限死循环，从而出现永不休止的爬取相同数据。</p><p>　　Scrapy-Redis自带的去重功能目前还未研究，效果如何暂不做评论；不过网上有很多关于修改源码通过实现去重逻辑，有兴趣的可查阅有关BloomFilter相关的资料。</p><h2 id="答谢"><a href="#答谢" class="headerlink" title="答谢"></a>答谢</h2><p>感谢<a href="https://github.com/sqaiyan/netmusic-node" target="_blank" rel="noopener">sqaiyan</a>在数据API上给予的灵感</p><p>感谢<a href="https://github.com/LiuXingMing/SinaSpider" target="_blank" rel="noopener">LiuXingMing</a>在分布式爬虫实现上给予的灵感</p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pandas.read_json()踩坑总结 &amp; 源码初探</title>
      <link href="/2018/09/16/Pandas-read-json-%E8%B8%A9%E5%9D%91%E6%80%BB%E7%BB%93-%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2/"/>
      <content type="html"><![CDATA[<p>　　基于实际工作中遇到的一种极端场景来分析Pandas.read_json()方法的源码实现；顺便站在个人学习和使用的角度出发，吐槽一下该方法底层设计的不合理之处。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>环境依赖：Python 2.7</p><p>样例数据(json文件)</p><p><img src="./样例数据.png" alt="样例数据"></p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>　　通过Pandas.read_json(jsonFilePath)方法读取json文件时，会出现数据内容发生奇怪的转变；Eg：假设样例数据的文件名为data.json，则执行pd.read_json(data.json)后的结果以及各列数据的数据类型分别如下图所示：</p><p><img src="./read_json解析结果.png" alt="read_json解析结果"></p><p><img src="./read_json结果数据类型.png" alt="read_json结果数据类型"></p><p>　　相较于原始数据集，经过该方法执行后的结果有两处不一致的地方：第一，userId和telephone这两列的数据类型由原本的String变成了int64；第二，<font color="red">userId字段的值发生了变化</font>。</p><h2 id="源码剖析"><a href="#源码剖析" class="headerlink" title="源码剖析"></a>源码剖析</h2><p>接下来将从深入源码来探究这种情况发生的原因；pd.read_json()的源码及其该方法之间的调用时序分别如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_json</span><span class="params">(path_or_buf=None, orient=None, typ=<span class="string">'frame'</span>, dtype=True,</span></span></span><br><span class="line"><span class="function"><span class="params">              convert_axes=True, convert_dates=True, keep_default_dates=True,</span></span></span><br><span class="line"><span class="function"><span class="params">              numpy=False, precise_float=False, date_unit=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Convert a JSON string to pandas object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    path_or_buf : a valid JSON string or file-like, default: None</span></span><br><span class="line"><span class="string">        The string could be a URL. Valid URL schemes include http, ftp, s3, and</span></span><br><span class="line"><span class="string">        file. For file URLs, a host is expected. For instance, a local file</span></span><br><span class="line"><span class="string">        could be ``file://localhost/path/to/table.json``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    orient</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * `Series`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - default is ``'index'``</span></span><br><span class="line"><span class="string">          - allowed values are: ``&#123;'split','records','index'&#125;``</span></span><br><span class="line"><span class="string">          - The Series index must be unique for orient ``'index'``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * `DataFrame`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - default is ``'columns'``</span></span><br><span class="line"><span class="string">          - allowed values are: &#123;'split','records','index','columns','values'&#125;</span></span><br><span class="line"><span class="string">          - The DataFrame index must be unique for orients 'index' and</span></span><br><span class="line"><span class="string">            'columns'.</span></span><br><span class="line"><span class="string">          - The DataFrame columns must be unique for orients 'index',</span></span><br><span class="line"><span class="string">            'columns', and 'records'.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * The format of the JSON string</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          - split : dict like</span></span><br><span class="line"><span class="string">            ``&#123;index -&gt; [index], columns -&gt; [columns], data -&gt; [values]&#125;``</span></span><br><span class="line"><span class="string">          - records : list like</span></span><br><span class="line"><span class="string">            ``[&#123;column -&gt; value&#125;, ... , &#123;column -&gt; value&#125;]``</span></span><br><span class="line"><span class="string">          - index : dict like ``&#123;index -&gt; &#123;column -&gt; value&#125;&#125;``</span></span><br><span class="line"><span class="string">          - columns : dict like ``&#123;column -&gt; &#123;index -&gt; value&#125;&#125;``</span></span><br><span class="line"><span class="string">          - values : just the values array</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    typ : type of object to recover (series or frame), default 'frame'</span></span><br><span class="line"><span class="string">    dtype : boolean or dict, default True</span></span><br><span class="line"><span class="string">        If True, infer dtypes, if a dict of column to dtype, then use those,</span></span><br><span class="line"><span class="string">        if False, then don't infer dtypes at all, applies only to the data.</span></span><br><span class="line"><span class="string">    convert_axes : boolean, default True</span></span><br><span class="line"><span class="string">        Try to convert the axes to the proper dtypes.</span></span><br><span class="line"><span class="string">    convert_dates : boolean, default True</span></span><br><span class="line"><span class="string">        List of columns to parse for dates; If True, then try to parse</span></span><br><span class="line"><span class="string">        datelike columns default is True; a column label is datelike if</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it ends with ``'_at'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it ends with ``'_time'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it begins with ``'timestamp'``,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it is ``'modified'``, or</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * it is ``'date'``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    keep_default_dates : boolean, default True</span></span><br><span class="line"><span class="string">        If parsing dates, then parse the default datelike columns</span></span><br><span class="line"><span class="string">    numpy : boolean, default False</span></span><br><span class="line"><span class="string">        Direct decoding to numpy arrays. Supports numeric data only, but</span></span><br><span class="line"><span class="string">        non-numeric column and index labels are supported. Note also that the</span></span><br><span class="line"><span class="string">        JSON ordering MUST be the same for each term if numpy=True.</span></span><br><span class="line"><span class="string">    precise_float : boolean, default False</span></span><br><span class="line"><span class="string">        Set to enable usage of higher precision (strtod) function when</span></span><br><span class="line"><span class="string">        decoding string to double values. Default (False) is to use fast but</span></span><br><span class="line"><span class="string">        less precise builtin functionality</span></span><br><span class="line"><span class="string">    date_unit : string, default None</span></span><br><span class="line"><span class="string">        The timestamp unit to detect if converting dates. The default behaviour</span></span><br><span class="line"><span class="string">        is to try and detect the correct precision, but if this is not desired</span></span><br><span class="line"><span class="string">        then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,</span></span><br><span class="line"><span class="string">        milliseconds, microseconds or nanoseconds respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    result : Series or DataFrame</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    filepath_or_buffer, _, _ = get_filepath_or_buffer(path_or_buf)</span><br><span class="line">    <span class="keyword">if</span> isinstance(filepath_or_buffer, compat.string_types):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            exists = os.path.exists(filepath_or_buffer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if the filepath is too long will raise here</span></span><br><span class="line">        <span class="comment"># 5874</span></span><br><span class="line">        <span class="keyword">except</span> (TypeError, ValueError):</span><br><span class="line">            exists = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists:</span><br><span class="line">            <span class="keyword">with</span> open(filepath_or_buffer, <span class="string">'r'</span>) <span class="keyword">as</span> fh:</span><br><span class="line">                json = fh.read()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            json = filepath_or_buffer</span><br><span class="line">    <span class="keyword">elif</span> hasattr(filepath_or_buffer, <span class="string">'read'</span>):</span><br><span class="line">        json = filepath_or_buffer.read()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        json = filepath_or_buffer</span><br><span class="line"></span><br><span class="line">    obj = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">'frame'</span>:</span><br><span class="line">        obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,</span><br><span class="line">                          keep_default_dates, numpy, precise_float,</span><br><span class="line">                          date_unit).parse()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> typ == <span class="string">'series'</span> <span class="keyword">or</span> obj <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(dtype, bool):</span><br><span class="line">            dtype = dict(data=dtype)</span><br><span class="line">        obj = SeriesParser(json, orient, dtype, convert_axes, convert_dates,</span><br><span class="line">                           keep_default_dates, numpy, precise_float,</span><br><span class="line">                           date_unit).parse()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> obj</span><br></pre></td></tr></table></figure><p><img src="./readJson方法间调用时序.png" alt="read_json方法间调用时序"></p><p>　　通过这段源码可以看出，read_json方法主要做了三件事：首先基于给定的参数做校验，然后获取指定url或流中的数据信息转化为jsonStr，最后一步对该jsonStr进行解析。用户可显示的通过typ字段来指定解析结果的类型(DataFrame or Series)。解析逻辑所对应的对象模型如下所示：</p><p><img src="./Parse对象模型.png" alt="Parse对象模型"></p><p>　　由于Series的解析逻辑比较简单，且实际工作中直接基于DataFrame的操作比较多，因此这里主要对jsonStr解析成DataFrame的过程做进一步的梳理。在第三步数据解析的过程中，<code>FrameParser.parse()</code>方法的本质其实是调用了父类Parse的parse方法，该方法的职能有三个：首先将jsonStr解析成DataFrame数据结构；其次对解析结果的轴做数据类型转化；最后<font color="red">尝试对数据进行类型转化</font>。源码及对应的方法间调用时序如下图所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># try numpy</span></span><br><span class="line">      numpy = self.numpy</span><br><span class="line">      <span class="keyword">if</span> numpy:</span><br><span class="line">          self._parse_numpy()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          self._parse_no_numpy()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.obj <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">      <span class="keyword">if</span> self.convert_axes:</span><br><span class="line">          self._convert_axes()</span><br><span class="line">      self._try_convert_types()</span><br><span class="line">      <span class="keyword">return</span> self.obj</span><br></pre></td></tr></table></figure><p><img src="/images/placeholder.png" alt="Parse.parse方法间调用时序" data-src="./Parse.parse方法间调用时序.png" class="lazyload"></p><p>　　在解析jsonStr时，首先会根据参数numpy来判断是否需要将数据反序列化为numpy数组类型；这个反序列化的过程是通过Pandas内部封装的json工具类的loads方法来实现的；然后将反序列化后的Dict对象经过DataFrame类进行数据初始化，从而得到该jsonFile所对应的DataFrame数据结构。由于<code>_parse_no_numpy()</code> 和<code>_parse_numpy()</code>这两个方法的原理类似，这里以<code>FrameParse._parse_numpy()</code>为例，看一下对应的源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_parse_numpy</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">    json = self.json</span><br><span class="line">    orient = self.orient</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> orient == <span class="string">"columns"</span>:</span><br><span class="line">        args = loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>, labelled=<span class="keyword">True</span>,</span><br><span class="line">                     precise_float=self.precise_float)</span><br><span class="line">        <span class="keyword">if</span> args:</span><br><span class="line">            args = (args[<span class="number">0</span>].T, args[<span class="number">2</span>], args[<span class="number">1</span>])</span><br><span class="line">        self.obj = DataFrame(*args)</span><br><span class="line">    <span class="keyword">elif</span> orient == <span class="string">"split"</span>:</span><br><span class="line">        decoded = loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                        precise_float=self.precise_float)</span><br><span class="line">        decoded = dict((str(k), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> compat.iteritems(decoded))</span><br><span class="line">        self.check_keys_split(decoded)</span><br><span class="line">        self.obj = DataFrame(**decoded)</span><br><span class="line">    <span class="keyword">elif</span> orient == <span class="string">"values"</span>:</span><br><span class="line">        self.obj = DataFrame(loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                                   precise_float=self.precise_float))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.obj = DataFrame(*loads(json, dtype=<span class="keyword">None</span>, numpy=<span class="keyword">True</span>,</span><br><span class="line">                                    labelled=<span class="keyword">True</span>,</span><br><span class="line">                                    precise_float=self.precise_float))</span><br></pre></td></tr></table></figure><p>　　<strong>注意这里的写法</strong>：父类Parse中是没有<code>_parse_no_numpy()</code> 和<code>_parse_numpy()</code>这两个方法的，也就是说是在父类调用子类的方法。其实不同于Java这类编程语言，在Python中需要从对象生成的角度来看待这个问题；因为此时的Parse类就是FrameParser，所以<code>self._parse_no_numpy()</code>的调用本质就是其实现类自身的方法，所以就有了这种看似奇怪的父调子写法。</p><p>　　当执行完数据解析后，我们已经得到DataFrame，那么先别着急往下看，在Debug下看看此时解析出来的结果如何：</p><p><img src="/images/placeholder.png" alt="parse解析结果" data-src="./parse解析结果.png" class="lazyload"></p><p><img src="/images/placeholder.png" alt="parse解析字段类型" data-src="./parse解析字段类型.png" class="lazyload"></p><p>　　对比发现，走到这一步时解析结果和字段类型都和我们原始的数据集保持一致，所以可以肯定数据的解析逻辑是没有问题的，那么跟着源码继续往下走，就来到frame轴类型转化的过程；截止目前个人还是不太明白这层处理的意义是什么；因为在对index和column进行数据类型转化时，index列的类型是int64，而column的名字也都是字符串从而导致尝试类型转化无效。所以对于这处有了解的环境补充和指教。因为这次的逻辑判断可通过显示的控制，且经过测试后发现执行对结果并无影响，因此在这里不做过多的讨论。</p><p>　　最后来看看parse的最后一个职能：尝试对数据进行类型转化。该方法在父类的实现只是简单的异常捕获，具体的处理逻辑在对应的子类中实现，在这里看一下FrameParser类中方法<code>_try_convert_types()</code>的源码实现和对应的方法间调用时序：</p><p><img src="/images/placeholder.png" alt="FrameParse._try_convert_types源码.png" data-src="./FrameParse._try_convert_types源码.png" class="lazyload"></p><p><img src="/images/placeholder.png" alt="try_convert_types时序" data-src="./try_convert_types时序.png" class="lazyload"></p><p>　　在FrameParse中，会对数据进行两次转化尝试：首先会尝试进行日期类型的转化，其次会对数据进行数值类型转化。在日期类型的尝试转化中，是基于特殊命名的列数据进行处理，具体包括列名以“_at”，“_time”结尾、或者以“timestamp”开头或者列名等于“modified”，“date”， “datetime”。因为这种处理对最终结果不会产生影响，所以在这里不做过多讨论。</p><p>　　跳过日期类型转化后，就来到最后一步，数据的数值类型转化尝试。方法<code>_process_converter()</code>可以抽象的理解为一个数据转化工具类，负责对数据集中的每一列数据按照指定的转化规则进行转化尝试；该方法的第一个参数类型是一个方法，作用就是指定需要对数据列做哪种转化。在这里传入父类的<code>Parse._try_convert_data()</code>方法，该方法的作用就是尝试将数据转化成数值类型；该方法的源码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_try_convert_data</span><span class="params">(self, name, data, use_dtypes=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                      convert_dates=True)</span>:</span></span><br><span class="line">    <span class="string">""" try to parse a ndarray like into a column by inferring dtype """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># don't try to coerce, unless a force conversion</span></span><br><span class="line">    <span class="keyword">if</span> use_dtypes:</span><br><span class="line">        <span class="keyword">if</span> self.dtype <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">            <span class="keyword">return</span> data, <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">elif</span> self.dtype <span class="keyword">is</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># dtype to force</span></span><br><span class="line">            dtype = (self.dtype.get(name)</span><br><span class="line">                     <span class="keyword">if</span> isinstance(self.dtype, dict) <span class="keyword">else</span> self.dtype)</span><br><span class="line">            <span class="keyword">if</span> dtype <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    dtype = np.dtype(dtype)</span><br><span class="line">                    <span class="keyword">return</span> data.astype(dtype), <span class="keyword">True</span></span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">return</span> data, <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> convert_dates:</span><br><span class="line">        new_data, result = self._try_convert_to_date(data)</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">            <span class="keyword">return</span> new_data, <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    result = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data.dtype == <span class="string">'object'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># try float</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = data.astype(<span class="string">'float64'</span>)</span><br><span class="line">            result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data.dtype.kind == <span class="string">'f'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> data.dtype != <span class="string">'float64'</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># coerce floats to 64</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                data = data.astype(<span class="string">'float64'</span>)</span><br><span class="line">                result = <span class="keyword">True</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># do't coerce 0-len data</span></span><br><span class="line">    <span class="keyword">if</span> len(data) <span class="keyword">and</span> (data.dtype == <span class="string">'float'</span> <span class="keyword">or</span> data.dtype == <span class="string">'object'</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># coerce ints if we can</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            new_data = data.astype(<span class="string">'int64'</span>)</span><br><span class="line">            <span class="keyword">if</span> (new_data == data).all():</span><br><span class="line">                data = new_data</span><br><span class="line">                result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># coerce ints to 64</span></span><br><span class="line">    <span class="keyword">if</span> data.dtype == <span class="string">'int'</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># coerce floats to 64</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = data.astype(<span class="string">'int64'</span>)</span><br><span class="line">            result = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data, result</span><br></pre></td></tr></table></figure><p>　　回顾一下文章一开始提到的例子，具体的调用方法为<code>pd.read_json(filePath)</code>，则通过查看源码的参数注解可知dtype默认为True，此时在方法<code>_try_convert_data</code>里，由于user_dtypes和dtype同为True，convert_dates为False，所以代码直接跳过前面的逻辑判断和时间类型转化尝试，直接进入数值类型的转化尝试中，读完源码就可以看到数据会先尝试转化成float64类型，然后尝试转化为int64类型。通过一步步的Debug，也终于找到问题发生的根源：当代码经过如下位置时，查看一下此时对应的数据结果，如下图所示：</p><p><img src="/images/placeholder.png" alt="str转float上溢" data-src="./str转float上溢.png" class="lazyload"></p><p>　　看到这也就真想大白了：基于<code>pd.read_json(path)</code>这种写法，底层会对每列数据进行数值类型转化尝试；又因为原始数据集中的userId是数值类型的字符串，所以在将Object转为float64时不会报错，从而再经过后面的int类型的转化，从而导致我们的最终看到的数据类型发生变化。我们可以看到telephone的类型发生了变化，但是数据类型缺没有发生改变，而userId的内容都发生的奇怪的变化，这个原因又是什么呢？</p><p>　　其实这个问题的本质和Python和Pandas就没太大关系了，要弄清这个原因，就需要从计算机存储浮点数的机制说起。因为Python的float类型是存在IEEE 745标准，因此这里的float64即就是双精度浮点数，所以在内存中，每个双精度浮点数所占用的总位数为64位，符号位占1位，阶数占11位，尾数占52位，那么：2<sup>52</sup>=4503599627370496，即双精度浮点数的有效位数为16位。由于userId是一个19位的字符串，所以在做类型转化的时候会因为浮点数上溢现象导致数据失真；这就是为什么经过<code>astype(&#39;float64&#39;)</code>后数据内容发生变化的原因。</p><p>　　既然在实际应用中，无法保证、要求或者约束原始数据集，那么如果规避这种因为浮点数上溢带来的数据失真的情况呢？我们再来看一下那个数据类型转化的方法<code>_try_converty_data()</code>的源码：</p><p><img src="/images/placeholder.png" alt="try_convert_data源码_解析判断" data-src="./try_convert_data源码_解析判断.png" class="lazyload"></p><p>　　通过阅读上下文的代码可知，user_dtyps恒为True，但是dtype可以让用户显示的指定，只是如果不指定默认为True，从而导致浮点数存储上溢的情况；当再次看到这里的判断逻辑不难发现，如果把dtype设置为False，则可以完全避免数据类型尝试转化的过程，从而可以保证数据的真实性和有效性；与此同时，通过查阅<code>pd.read_josn()</code>的参数注解可知道，dtype可以为Boolean型，同样也可以为Dict类型，结合源码可以发现可以自定义指定需要转化的数据列和数据类型；这样我们也可以通过显示的指定userId的转化类型来规避这种上溢带来的问题。上述两种方法都是有效的，在这里我以第二种为例，重修修改一下代码：</p><p><img src="/images/placeholder.png" alt="read_json自定义dtype" data-src="./read_json自定义dtype.png" class="lazyload"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>　　在基于pandas处理数据时，尤其是通过读取外部数据源来做分析时，一定要注意数据类型的转化问题，避免出现类似这种因为底层数据存储溢出导致数据失真、或者数据类型变化导致的错误【Eg：pd.read_json()，pd.read_csv()】。</p><p>　　最后在顺便吐槽一下，pandas底层的这个设定也太过于奇葩；应该将read_json()方法中的参数dtype的默认值设置为False，让用户去显示的做类型转化；而不应该为了凸显在数据处理上的便利性，去容忍这种这种数据溢出的潜在Bug(亦或是pandas的开发者压根没意识到这个问题 ~~~ 哈哈 ^v^)。</p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于centOS 7搭建FTP服务器</title>
      <link href="/2018/07/03/%E5%9F%BA%E4%BA%8EcentOS-7%E6%90%AD%E5%BB%BAFTP%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <content type="html"><![CDATA[<p>分别基于匿名用户、本地用户、虚拟用户这三种登录模式详解FTP的搭建过程</p><a id="more"></a><p>　　在开始接触服务器搭建的时候，参考过网上很多资料，不过内容五花八门，而且表述也不清楚。归根结底，是因为自己在动手搭建的时候并没有对FTP有一个初步的认识；没有正确理解参考博客所对应的配置模式，从而导致同时参考多份博客的配置但最终结果已然无效。所以在此总结一下自己的搭建心得，分别对不同的登录模式进行归纳总结。</p><p>关于FTP的工具类详见<a href="https://github.com/YHYR/SpringBoot-FTPDemo" target="_blank" rel="noopener">Github</a></p><h1 id="安装FTP"><a href="#安装FTP" class="headerlink" title="安装FTP"></a>安装FTP</h1><p>首先检查本机是否装有FTP服务器，命令：<code>rpm -qa | grep vsftpd</code>；效果如下图所示：</p><p><img src="./1.png" alt="ftp服务查看"></p><p>如果没有，则执行如下命令进行安装:</p><p><code>yum -y install vsftpd</code></p><p>若想卸载FTP，执行命令：<code>rpm -e vsftpd-***</code>；执行效果如下图所示：</p><p><img src="./2.png" alt="卸载ftp服务"></p><p><strong><em>删除后会保留主要的配置文件，并命名为.rpmsave后缀；如不需要，则可自行手动删除</em></strong>。</p><h1 id="防火墙、SELinux-设置"><a href="#防火墙、SELinux-设置" class="headerlink" title="防火墙、SELinux 设置"></a>防火墙、SELinux 设置</h1><h3 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h3><p>首先保证开启firewalld服务：<code>systemctl start firewalld.service</code></p><p>然后分别执行如下命令</p><p><code>firewall-cmd --permanent --zone=public --add-service=ftp</code></p><p><code>firewall-cmd --reload</code></p><p>如果执行firewall-cmd命令报错：<code>ImportError: No module named gi.repository</code>，如下所示：</p><p><img src="./3.png" alt="firewalld报错-"></p><p>则可通过修改/usr/bin/firewall-cmd文件，将第一行的<code>#!/usr/bin/python -Es</code>修改为<code>#!/usr/bin/python2.7 -Es</code>即可解决该问题，因为CentOS 7默认的python版本是2.7</p><p><img src="./4.png" alt="firewall-cmd文件修改"></p><h3 id="SELinux设置"><a href="#SELinux设置" class="headerlink" title="SELinux设置"></a>SELinux设置</h3><blockquote><p>a) 临时关闭：<code>setenforce 0</code></p><p>b) 永久关闭：修改/etc/selinux/config文件中，设置SELINUX=disable，并重启服务器</p></blockquote><h1 id="匿名用户登录"><a href="#匿名用户登录" class="headerlink" title="匿名用户登录"></a>匿名用户登录</h1><p>　　用户登录时不需要用户名和密码，就可直接进入FTP服务器；默认的用户名为ftp，密码为空；在该模式下，默认的文件存储路径为：/var/ftp</p><p>　　该目录下有一个pub文件夹，若想上传文件到该目录下，则需要修改pub目录的所属组用户信息和目录权限信息；若要上传目录到当前根目录(即：/var/ftp)，则需要修改ftp目录的组用户信息和权限信息；这里以pub目录为例：</p><blockquote><p>修改目录的所属组用户信息：<code>chown -R ftp:ftp /var/ftp/pub</code></p><p>修改目录的权限信息：<code>chmod -R 777 /var/ftp/pub</code></p></blockquote><p>　　其次，在/etc/vsftpd下修改ftp的配置文件vsftpd.conf；在修改前，尽量养成修改原始配置文件的习惯(<code>cp vsftpd.conf vsftpd.conf.bak</code>)。</p><p>　　默认情况下FTP的登录模式就是匿名登录，即：<code>anonymous_enable=YES</code>；如下图所示：</p><p><img src="./5.png" alt="默认配置文件"></p><p>　　在配置文件中添加文件根目录、上传权限和写权限，如下图所示：</p><p><img src="/images/placeholder.png" alt="匿名模式配置文件" data-src="./6.png" class="lazyload"></p><p>　　到此匿名登录的配置已完成，可以通过<code>systemctl start vsftpd.service</code>、<code>systemctl stop vsftpd.service</code>、<code>systemctl restart vsftpd.service</code>分别开启、关闭和重启ftp服务，进而可以开始的上传和下载任务。</p><h1 id="本地用户登录"><a href="#本地用户登录" class="headerlink" title="本地用户登录"></a>本地用户登录</h1><p>　　本地用户登录是指使用当前系统中所存在的用户来作为登录FTP服务器的认证信息。</p><p>　　FTP默认是开启了本地用户登录模式，即：<code>local_enable=YES</code>；如下图所示：</p><p><img src="/images/placeholder.png" alt="本地登录模式原始配置信息" data-src="./7.png" class="lazyload"></p><p>　　目前系统中存在一个用户：yhyr</p><p>　　修改FTP配置文件 <code>vi /etc/vsftpd/vsftpd.conf</code>，添加如下两行配置(需要关闭匿名登录模式，即设置anonymous_enable=NO)：</p><p><img src="/images/placeholder.png" alt="本地用户登录新增配置" data-src="./8.png" class="lazyload"></p><p>　　<code>chroot_local_user=YES</code>表示限制所有用户都只能访问该用户的home目录；前提条件是配置文件里没有配置local_root属性；如果配置了local_root属性，则该用户只能访问local_root所指向的路径。当配置了chroot_local_user=YES，则一定要顺便配置一下allow_writeable_chroot=YES；否则在用户登录的时候会报如下错误：</p><p><img src="/images/placeholder.png" alt="本地用户登录7" data-src="./9.png" class="lazyload"></p><p>　　到此本地登录模式已经基本配置完成，接下来验证一下；在终端连接ftp：ftp localhost，如下所示：</p><p><img src="/images/placeholder.png" alt="本地用户连接ftp" data-src="./10.png" class="lazyload"></p><p>　　按照提示输入用户名：yhyr</p><p><img src="/images/placeholder.png" alt="本地用户登录输入用户名" data-src="./11.png" class="lazyload"></p><p>　　输入该用户的密码，反馈信息如下：</p><p><img src="/images/placeholder.png" alt="本地用户登录成功反馈信息" data-src="./12.png" class="lazyload"></p><p>　　这样就实现了用本地用户登录ftp；因为配置了chroot_local_user=YES，所以当前登录的目录位置即就是用户yhyr的根目录，即：/home/yhyr；且只能访问当前目录及其子目录，并不能访问其他用户的目录或者系统目录(eg：执行cd ..的操作是无效的)</p><p><img src="/images/placeholder.png" alt="本地用户无权限访问其他目录" data-src="./13.png" class="lazyload"></p><h2 id="本地用户访问权限控制"><a href="#本地用户访问权限控制" class="headerlink" title="本地用户访问权限控制"></a>本地用户访问权限控制</h2><p><strong>配置项解析</strong></p><blockquote><p><code>userlist_enable=YES</code>：表示用/etc/vsftpd下的user_list名单来限制可访问的用户</p><p><code>userlist_deny=NO</code>：表示只允许user_list名单中的用户可以访问；相反当<code>userlist_deny=YES</code>时，表示user_list名单中的用户不可访问</p></blockquote><p>　　user_list是安装ftp时默认带有的一个文件，里面主要包含了诸如root、sync、games、nobody等系统用户，如下图所示：</p><p><img src="/images/placeholder.png" alt="user_list信息" data-src="./14.png" class="lazyload"></p><p>　　Eg：在配置文件中添加上述两项配置项，如下图所示：</p><p><img src="/images/placeholder.png" alt="本地用户添加登录权限控制" data-src="./15.png" class="lazyload"></p><p>　　重启服务后，分别用yhyr用户和root用户来做测试，你会发现用yhyr用户登录时在输入完用户名后就直接报错：<font color="red">530 Permission denied<font>；而用root用户登录时，当输入完密码后也会报错：<font color="red">530 Login incorrect</font>；如下图所示：</font></font></p><p><img src="/images/placeholder.png" alt="本地用户登录权限验证" data-src="./16.png" class="lazyload"></p><p>　　yhyr用户在登录时在直接拒绝就正是因为添加了登录权限的配置，因为userlist_deny设置为NO，所以除user_list中所包含的用户外，其他用户一律拒绝，因此会报Permission denied错误；而root用户登录时，你会发现该用户其实是有访问权限的，因为此时登录的root用户不像刚才的yhyr用户，是给了你输入密码的机会，但是当输入完密码后，报出的错误Login incorrect并不是因为该用户没权限或者改配置没生效，而是因为系统默认是禁用/etc/vsftpd/ftpusers中的用户，查看ftpusers可以看到，root用户模式是存在于ftpusers中的。</p><p><img src="/images/placeholder.png" alt="系统禁用ftpusers中的用户" data-src="./17.png" class="lazyload"></p><p>这个问题其实很好解决，而且解决的方案也很多：</p><p>　　方案一：对比观察user_list和ftpusers可以发现其实内容是一模一样的，所以不难看出设计者是觉得这些系统级的用户是不应该暴露出去供外部使用的；而我们的实际应用场景也应该是分配一个或多个低权限的账户供用户使用，因此可以改变原有的配置项，在开启用户登录认证(userlist_enable=YES)的同时，设置userlist_deny为YES，这样默认的系统级用户则变为不可用的，就可以使用自定用的用户来作为认证信息。</p><p>　　方案二：在设置userlist_deny为NO的同时，把需要授权的用户名添加到user_list中，并保证在ftpusers中不存在即可；例如上述例子中如果想让root用户成功登陆，则只需要把ftpusers中的root那一行删除即可(<em>不建议使用该方法</em> )。</p><h2 id="自定义数据存放路径"><a href="#自定义数据存放路径" class="headerlink" title="自定义数据存放路径"></a><font color="red">自定义数据存放路径</font></h2><p><strong>配置项解析</strong></p><blockquote><p><code>chroot_local_user=YES</code>：代表使用登陆用户的home目录作为路径，eg：用yhyr用户登录，则默认的文件路径为：/home/yhyr</p><p><code>local_root=xxx</code>：代表用户登录时指定文件目录为local_root所设置的目录；且local_root配置项的优先级高于chroot_local_user，即就是当同时设置了这两个参数，以local_root配置项为准</p></blockquote><p><em><font color="red">local_root所指定的路径和所登录的用户的权限信息必须匹配，否则会出现由于文件权限问题不对而导致登录失败的问题</font></em></p><p>　　Eg：设置local_root=/home/test，并用yhyr用户做测试，因为/home/test目录所属的用户组信息不是yhyr，所以yhyr用户并没有访问该目录的权限，因此在此场景下登录会报错：</p><p><img src="/images/placeholder.png" alt="用户文件路径权限不对导致登录失败" data-src="./18.png" class="lazyload"></p><h2 id="多用户数据目录隔离"><a href="#多用户数据目录隔离" class="headerlink" title="多用户数据目录隔离"></a><font color="red">多用户数据目录隔离</font></h2><p>　　在实际工作中，往往有这样的需求：一个FTP服务器会设置多个用户，且希望每个用户的文件存放路径都不一样。接下来分析一下这种业务场景如何实现。</p><p>　　首先在系统中新建一个test用户：<code>useradd -d /home/test test</code></p><p>　　然后设置test用户的密码：<code>passwd test</code></p><p>　　在这里首先注释掉上文中所配置的有关登录权限控制的两行配置，并重启服务后，用test用户测试，可以看到登录没有问题：</p><p><img src="/images/placeholder.png" alt="test用户登录" data-src="./19.png" class="lazyload"></p><p>　　因为我们配置了<code>chroot_local_user=YES</code>，所以test用户登陆进来后肯定是在/home/test目录下，这样yhyr用户和test用户的目录这不正好不冲突吗？这个问题不就不是个问题吗？</p><p>　　实则不然，结合实际的应用场景，我们不难发现，在实际的生产服务器里，往往都是会外挂一个容量很大的磁盘用来存放数据，而操作系统中诸如/home这类目录的大小通常都很小，而Linux的用户根目录也都是在/home下的，如果一次来作为存放数据的目录，想必要不了多久就会磁盘爆掉；因此我这里说指的目录隔离是基于此业务背景下，结合上文提到的<code>local_root</code>参数来实现多用户的目录隔离功能。</p><p>　　通过上文我们可以知道，通过local_root可以指定我们的数据目录，但是从上述的分析中可以看出是只能指定一个路径，对于多个用户登录，就必然会有一个或多个用户登录时出现“500  cannot change directory”的错误。如何实现目录隔离呢？在这里需要介绍一个新的配置项：</p><blockquote><p>user_config_dir：该配置项指定一个文件夹路径，该文件夹下存放各本地用户的配置文件信息；用户配置文件的名字与用户名保持一致</p></blockquote><h3 id="Step-1：指定用户数据存储目录"><a href="#Step-1：指定用户数据存储目录" class="headerlink" title="Step 1：指定用户数据存储目录"></a>Step 1：指定用户数据存储目录</h3><p>　　在根目录下新建一个data文件夹，模拟我们实际应用中的外挂数据盘：<code>mkdir /data</code></p><p>　　在该目录下创建ftp_data/test和ftp_data/yhyr文件夹，分别代表test用户和yhyr用户所对应的数据存放目录，然后分别在test和yhyr目录下各创建一个文件，便于后面的演示，如下图所示：</p><p><img src="/images/placeholder.png" alt="多用户隔离数据目录" data-src="./20.png" class="lazyload"></p><h3 id="Step-2：指定用户的数据存储路径"><a href="#Step-2：指定用户的数据存储路径" class="headerlink" title="Step 2：指定用户的数据存储路径"></a>Step 2：指定用户的数据存储路径</h3><p>　　然后在/etc/vsftpd路径下新建一个userconf目录，并在该目录下分别新建一个test文件和yhyr文件(文件名和用户名保持一致)，分别在不同的文件中配置local_root参数，用来指定该用户的数据存储路径：</p><p><img src="/images/placeholder.png" alt="user_config_dir文件配置" data-src="./21.png" class="lazyload"></p><p>　　并在配置文件中添加user_config_dir配置项，指向我们设定的userconf目录：</p><p><img src="/images/placeholder.png" alt="添加user_config_dir配置项" data-src="./22.png" class="lazyload"></p><p>　　重启服务后，分别用test用户和yhyr用户进行验证：</p><p><img src="/images/placeholder.png" alt="验证多用户目录隔离" data-src="./23.png" class="lazyload"></p><p>到此本地用户登录的配置以分享完成</p><h1 id="虚拟用户登录"><a href="#虚拟用户登录" class="headerlink" title="虚拟用户登录"></a>虚拟用户登录</h1><p>　　顾名思义，该用户不是真实存在于系统中的用户；但是<font color="red">与匿名用户登录不同，虚拟用户登录时需要密码认证</font>。当你了解了上文提到过的本地用户登录的配置原理后，就会很容易理解虚拟用户的配置。</p><p>具体配置如下所示(需要关闭匿名登录模式，即设置anonymous_enable=NO)：</p><p><img src="/images/placeholder.png" alt="虚拟用户配置文件" data-src="./24.png" class="lazyload"></p><p><strong>配置项解析</strong></p><blockquote><p><code>guest_enable=YES</code>：表示开始虚拟用户登录模式</p><p><code>guest_username=yhyr</code>：指定虚拟用户所依赖的本地用户的用户名</p><p><code>user_config_dir=xxx</code>：指定不同虚拟用户的详细配置信息</p></blockquote><p>具体操作与本地用户中的多用户数据目录隔离的配置方式类似</p><h3 id="Step-1-创建虚拟用户的数据存储目录"><a href="#Step-1-创建虚拟用户的数据存储目录" class="headerlink" title="Step 1: 创建虚拟用户的数据存储目录"></a>Step 1: 创建虚拟用户的数据存储目录</h3><p>假设有两个虚拟用户：</p><p>guest_user_1对应的数据存储目录为/data/ftp_data/guest_user_1</p><p>guest_user_1对应的数据存储目录为/data/ftp_data/guest_user_2</p><font color="red">注：需要把数据目录的用户组信息设置为guest_username所指定的用户</font><p>Eg：<code>chown yhyr:yhyr guest_user_1</code>、<code>chown yhyr:yhyr guest_user_2</code></p><h3 id="Step-2：指定虚拟用户的数据存储路径"><a href="#Step-2：指定虚拟用户的数据存储路径" class="headerlink" title="Step 2：指定虚拟用户的数据存储路径"></a>Step 2：指定虚拟用户的数据存储路径</h3><p>　　在/etc/vsftpd目录下新建一个guestuserconf目录，并在该目录下分别新建两个文件：guest_user_1和guest_user_2(文件名和虚拟用户的用户名保持一致)。在文件中添加local_root配置项指定该虚拟用户的数据存储路径：</p><p><img src="/images/placeholder.png" alt="虚拟用户user_config_dir配置" data-src="./25.png" class="lazyload"></p><h3 id="Step-3：设置虚拟用户的用户名和密码"><a href="#Step-3：设置虚拟用户的用户名和密码" class="headerlink" title="Step 3：设置虚拟用户的用户名和密码"></a>Step 3：设置虚拟用户的用户名和密码</h3><p>　　<font color="red">首先在/etc/vsftpd下新建一个guest_user_passwd文件</font>，该文件记录虚拟用户的用户名和密码信息(<strong>注：奇数行为用户名，偶数行为密码</strong>)，如下图所示，设置guest_user_1的密码为123456，设置guest_user_2的密码为abcdef</p><p><img src="/images/placeholder.png" alt="虚拟登录用户名和密码配置" data-src="./26.png" class="lazyload"></p><p><font color="red">然后生成虚拟用户认证的db文件</font>，命令如下所示：</p><p><code>db_load -T -t hash -f /etc/vsftpd/guest_user_passwd /etc/vsftpd/guest_user_passwd.db</code></p><p>　　<font color="red">最后修改/etc/pam.d/vsftpd文件，对虚拟用户授权</font>。注释掉<code>auth required pam_shells.so</code>、<code>auth include password-auth</code>、<code>account include password-auth</code>；并追加如下两行：  <code>auth required pam_userdb.so db=/etc/vsftpd/guest_user_passwd</code>和<code>account required pam_userdb.so db=/etc/vsftpd/guest_user_passwd</code></p><p><img src="/images/placeholder.png" alt="虚拟模式修改vsftpd文件" data-src="./27.png" class="lazyload"></p><p>然后重启服务，分别用guest_user_1和guest_user_2用户验证：</p><p><img src="/images/placeholder.png" alt="虚拟登录验证" data-src="./28.png" class="lazyload"></p><p>　　登录验证已经ok了，接下来只需要对虚拟用户赋予文件的读写权限即可。分别修改guestuserconf中各虚拟用户的配置文件，追加如下配置项，就可以正常的上传、下载和新建目录/文件。</p><blockquote><p>write_enable=YES</p><p>anon_upload_enable=YES</p><p>anon_other_write_enable=YES</p><p>anon_mkdir_write_enable=YES</p></blockquote><p><img src="/images/placeholder.png" alt="虚拟用户文件权限配置" data-src="./29.png" class="lazyload"></p>]]></content>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> FTP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于Python初探Linux下的僵尸进程和孤儿进程(三)</title>
      <link href="/2018/06/07/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%B8%89/"/>
      <content type="html"><![CDATA[<p>基于kafka+python实现消息多进程消费的应用场景探究新建子进程时僵尸进程自动消除的原因，并由此初探multiprocessing.Process.start()源码。</p><a id="more"></a><h1 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h1><p>　　在实现kafka消息的多进程消费时(即主进程用来获取消息，每条消息都会新起一个子进程来执行具体的业务逻辑)，存在新起一个子进程时会消除系统中遗留僵尸进程的情况，具体问题如下所述：</p><ul><li>a) 当消费一条消息时会生成一个子进程，且子进程结束后会变成僵尸进程；当再消费一条消息时，之前遗留的僵尸进程会消除，同时重新生成一个子进程来执行业务逻辑，结束后又变成僵尸进程。(以此类推)</li><li>b) 如果一次性消费多条消息，则会一次性生成多个子进程，且运行结束后会多个子进程均会变成僵尸进程；当再消费一条(多条)消息时，之前系统中遗留的多个僵尸进程均会被清除，并重新产生一个(多个)子进程来执行业务逻辑，结束后又会变成一个(多个)僵尸进程</li></ul><p>　　此应用场景的代码是<strong>基于未主动剔除僵尸进程的前提下</strong>实现的，<font color="red">重点讨论僵尸进程的自动消除的原因</font>；样例代码如下所示(若要探究如何消除僵尸进程，可详见<a href="https://yhyr.github.io/2018/06/06/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%BA%8C/" target="_blank" rel="noopener">传送门</a>)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConsumerUtil</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, broker_list, topic_name, group_name=<span class="string">'consumer_group_1'</span>, api_version=<span class="string">'0.10'</span>, auto_offset_reset=<span class="string">'latest'</span>)</span>:</span></span><br><span class="line">        self.broker_list = broker_list</span><br><span class="line">        self.topic_name = topic_name</span><br><span class="line">        self.group_name = group_name</span><br><span class="line">        self.api_version = api_version</span><br><span class="line">        self.auto_offset_reset = auto_offset_reset</span><br><span class="line"></span><br><span class="line">        self.consumer = KafkaConsumer(self.topic_name, group_id=self.group_name, bootstrap_servers=self.broker_list, enable_auto_commit=<span class="keyword">True</span>, api_version=self.api_version, auto_offset_reset=self.auto_offset_reset)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">consumer_fun</span><span class="params">(self, message_consumer)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> msg <span class="keyword">in</span> self.consumer:</span><br><span class="line">            message_consumer(msg.value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, broker_list, topic_name)</span>:</span></span><br><span class="line">        self.broker_list = broker_list</span><br><span class="line">        self.topic_name = topic_name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">consume_task</span><span class="params">(self, msg)</span>:</span></span><br><span class="line">        p = ChildProcess(msg)</span><br><span class="line">        print(<span class="string">'main process fork a new child process'</span>)</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process pid=&#123;0&#125;, ppid=&#123;1&#125; Begin'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        ConsumerUtil(self.broker_list, self.topic_name).consumer_fun(self.consume_task)</span><br><span class="line">        print(<span class="string">'main process pid=&#123;0&#125;, ppid=&#123;1&#125; End'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, msg)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.msg = msg</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125; Begin consumer msg, '</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125; Is being consumer msg=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), self.msg))</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125; End consumer msg'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    action = MainProcess(<span class="string">'127.0.0.1:9092'</span>, <span class="string">'demo_topic'</span>)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure><h1 id="场景抽象"><a href="#场景抽象" class="headerlink" title="场景抽象"></a>场景抽象</h1><p>　　为了方便举例，将上述实际业务场景抽象成一个简单的demo：当主进程开始启动时，会新建一个子进程，此时子父进程是并行执行；当主进程执行了10秒后会再启动一个子进程(此处模拟再次消费kafka消息)，在新建子进程的时候上一个子进程已经结束；样例代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> signal</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, main_process_time, child_process_time)</span>:</span></span><br><span class="line">        self.main_process_time = main_process_time</span><br><span class="line">        self.child_process_time = child_process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        p = ChildProcess(self.child_process_time)</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.main_process_time):</span><br><span class="line">            print(<span class="string">'main process, pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">10</span>:</span><br><span class="line">                p = ChildProcess(self.child_process_time)</span><br><span class="line">                p.start()</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'main process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.process_time):</span><br><span class="line">            print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'child process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main_process_time = <span class="number">30</span></span><br><span class="line">    child_process_time = <span class="number">5</span></span><br><span class="line">    action = MainProcess(main_process_time, child_process_time)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure><p>代码的执行逻辑如下所述：</p><p>主进程启动后初始化一个子进程(主进程的执行周期远大于子进程)，当子进程尚未结束时，控制台的输出结果和进程状态如下图所示(<font color="red">注意子进程的进程状态</font>)：</p><p><img src="./第一次新建子进程且未执行完成.png" alt="第一次新建子进程且未执行完成"></p><p>当子进程结束后，父进程继续执行且尚未第二次新建子进程的时候，控制台的输出结果和进程状态如下图所示(<font color="red">注意子进程的进程状态</font>)：</p><p><img src="./第一次新建子进程且子进程执行结束.png" alt="第一次新建子进程且子进程执行结束"></p><p>当父进程第二次新建一个子进程，且子父进程并行执行时，控制台的输出结果和进程状态如下图所示(<font color="red">注意子进程的进程号</font>)：</p><p><img src="./第二次新建子进程且未执行完成.png" alt="第二次新建子进程且未执行完成"></p><p>当第二次新建的子进程结束且父进程尚未结束时，控制台的数据结果和进程状态如下图所示(<font color="red">注意子进程的进程状态</font>)：</p><p><img src="./第二次新建子进程且子进程执行完成.png" alt="第二次新建子进程且子进程执行完成"></p><h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><p>　　根据实验现象不难看出，每当新建一个子进程的时候，就会清楚掉之前所有的僵尸进程(特指该父进程下的所有僵尸进程)。而造成此现象的真正原因就在于新起子进程的这个动作。基于multiprocessing新建子进程的方式是p.start()，该方法的源码如下所示：</p><p><img src="./start源码.png" alt="start源码"></p><p>　看源码可知start主要干了三件事：</p><ul><li>1) 调用_cleanup()方法</li><li>2) 基于Popen初始化一个进程</li><li>3) 将初始化的进程加到当前进程额子进程列表里。</li></ul><p>而上述实验现象产生的根本原因就在与这个_cleanup()方法。首先看一下该方法的源码：</p><p><img src="/images/placeholder.png" alt="cleanup源码" data-src="./cleanup源码.png" class="lazyload"></p><p>　　代码逻辑也很简单，遍历当前进程的子进程列表，调用子进程的poll()方法(该方法其实就是调用os.waitpid)，如果有返回状态信息，则代表该子进程是僵尸进程且已被系统清除掉，则会将该子进程从子进程列表中移除。这就是为什么每当新建一个子进程的时候，系统中遗留的僵尸进程会被清除而非一直存在。</p><p>　　接下来一起了解一下Python的Popen类；这个类在start、join和_cleanup方法中都有出现，Popen的作用其实就是新建一个进程。因为multiprocessing是跨平台的，所以在forking模块下分别基于Windows平台和非Windows平台各实现了一个Popen类，用来新建子进程，不同平台的Popen实现大致对比图如下所示：</p><p><img src="/images/placeholder.png" alt="Popen不同系统对比" data-src="./Popen不同系统对比.png" class="lazyload"></p><p>由于实际的工作都是在Linux上运行的，所以在这里着重看一下Linux上的具体实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unix</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> sys.platform != <span class="string">'win32'</span>:</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">    exit = os._exit</span><br><span class="line">    duplicate = os.dup</span><br><span class="line">    close = os.close</span><br><span class="line"></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># We define a Popen class similar to the one from subprocess, but</span></span><br><span class="line">    <span class="comment"># whose constructor takes a process object as its argument.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Popen</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_obj)</span>:</span></span><br><span class="line">            sys.stdout.flush()</span><br><span class="line">            sys.stderr.flush()</span><br><span class="line">            self.returncode = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">            self.pid = os.fork()</span><br><span class="line">            <span class="keyword">if</span> self.pid == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">'random'</span> <span class="keyword">in</span> sys.modules:</span><br><span class="line">                    <span class="keyword">import</span> random</span><br><span class="line">                    random.seed()</span><br><span class="line">                code = process_obj._bootstrap()</span><br><span class="line">                sys.stdout.flush()</span><br><span class="line">                sys.stderr.flush()</span><br><span class="line">                os._exit(code)</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">poll</span><span class="params">(self, flag=os.WNOHANG)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> self.returncode <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        pid, sts = os.waitpid(self.pid, flag)</span><br><span class="line">                    <span class="keyword">except</span> os.error <span class="keyword">as</span> e:</span><br><span class="line">                        <span class="keyword">if</span> e.errno == errno.EINTR:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                        <span class="comment"># Child process not yet created. See #1731717</span></span><br><span class="line">                        <span class="comment"># e.errno == errno.ECHILD == 10</span></span><br><span class="line">                        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span> pid == self.pid:</span><br><span class="line">                    <span class="keyword">if</span> os.WIFSIGNALED(sts):</span><br><span class="line">                        self.returncode = -os.WTERMSIG(sts)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">assert</span> os.WIFEXITED(sts)</span><br><span class="line">                        self.returncode = os.WEXITSTATUS(sts)</span><br><span class="line">            <span class="keyword">return</span> self.returncode</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wait</span><span class="params">(self, timeout=None)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> timeout <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> self.poll(<span class="number">0</span>)</span><br><span class="line">            deadline = time.time() + timeout</span><br><span class="line">            delay = <span class="number">0.0005</span></span><br><span class="line">            <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">                res = self.poll()</span><br><span class="line">                <span class="keyword">if</span> res <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                remaining = deadline - time.time()</span><br><span class="line">                <span class="keyword">if</span> remaining &lt;= <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                delay = min(delay * <span class="number">2</span>, remaining, <span class="number">0.05</span>)</span><br><span class="line">                time.sleep(delay)</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">terminate</span><span class="params">(self)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> self.returncode <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    os.kill(self.pid, signal.SIGTERM)</span><br><span class="line">                <span class="keyword">except</span> OSError, e:</span><br><span class="line">                    <span class="keyword">if</span> self.wait(timeout=<span class="number">0.1</span>) <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="meta">        @staticmethod</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">thread_is_spawning</span><span class="params">()</span>:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br></pre></td></tr></table></figure><p>　　看源码可知，multiprocessing适配类Unix平台的本质是采用fork(对Linux进程了解的小伙伴应该都很熟悉fork)，类Unix平台的Popen类中最主要的方法就是poll()；因为在外部直接调用p.join()其实就是调用Popen.wait()方法，而Popen.wait()底层调用的就是Popen.poll()；外部调用p.start()其实就是首先调用Popen.poll()实现僵尸进程的消除，然后初始化一个Popen从而实现新建一个子进程。</p><p>　　接下来分析一下Popen类：初始化Popen时，首先会调用Unix/Linux的fork来新建一个子进程；了解过Linux进程的人都知道，调用fork后会产生一个子进程且有两个返回值，父进程的返回值为子进程的进程id，子进程返回0；可以将fork的返回值理解为所产生的子进程的pid，因为经过fork后，原本的父进程就拥有了子进程，所以父进程的返回值为子进程的pid；因为所产生的子进程没有自己的子进程，所以它的返回值为0；因此在初始化Popen时，如果fork后当前进程为父进程则直接忽略不做处理，如果是子进程，则会首先通过<code>code = process_obj._bootstrap()</code>获取到父进程的pid，然后调用<code>os._exit(code)</code>强制退出主进程，从而保证经过初始化后只有一个新建的子进程。</p><p>　　因为wait方法的本质还是调用poll方法，所以在这里重点看一点poll方法：调用系统的os.waitpid()方法来释放子进程的退出状态信息，如果成功释放则函数返回退出状态码returncode；反之如果子进程并未结束，则直接退出并返回None。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>　　multiprocessing基于Linux平台实现多进程实则是基于fork来新建子进程的；调用p.start()的实质就是new一个Popen类(该类返回新建的子进程，并关闭对应的父进程)；与此同时p.start()会主动对子进程列表做一次清理操作(该操作是非阻塞的)；调用p.join()的本质是调用forking模块的Popen.wait()方法(该操作是阻塞的)。所以理解Popen是了解Python-multiprocessing的一个比较重要的前提。附上proces模块和forking模块之间的对象模型图。</p><p><img src="/images/placeholder.png" alt="process对象模型图" data-src="./process对象模型图.png" class="lazyload"></p><h2 id="未完待续"><a href="#未完待续" class="headerlink" title="未完待续"></a>未完待续</h2><p>常见的几种进程退出的方式对比分析(sys.exit(), os._exit())</p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> 多进程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于Python初探Linux下的僵尸进程和孤儿进程(一)</title>
      <link href="/2018/06/07/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%B8%80/"/>
      <content type="html"><![CDATA[<p><em>通过对比子父进程的执行周期来详细讨论僵尸进程产生的原因和规避方法</em></p><a id="more"></a><p>样例代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, main_process_time, child_process_time)</span>:</span></span><br><span class="line">        self.main_process_time = main_process_time</span><br><span class="line">        self.child_process_time = child_process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        p = ChildProcess(self.child_process_time)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.main_process_time):</span><br><span class="line">            print(<span class="string">'main process, pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'main process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.process_time):</span><br><span class="line">            print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'child process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main_process_time = <span class="number">5</span></span><br><span class="line">    child_process_time = <span class="number">10</span></span><br><span class="line">    action = MainProcess(main_process_time, child_process_time)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure><h1 id="业务场景及现象描述"><a href="#业务场景及现象描述" class="headerlink" title="业务场景及现象描述"></a>业务场景及现象描述</h1><h2 id="场景一：子进程的运行周期大于父进程"><a href="#场景一：子进程的运行周期大于父进程" class="headerlink" title="场景一：子进程的运行周期大于父进程"></a>场景一：子进程的运行周期大于父进程</h2><h3 id="子进程不调用join-方法：无僵尸进程存在"><a href="#子进程不调用join-方法：无僵尸进程存在" class="headerlink" title="子进程不调用join()方法：无僵尸进程存在"></a>子进程不调用join()方法：无僵尸进程存在</h3><p>样例代码中main_process_time代表主进程运行时长，child_process_time代表子进程运行时长；并注释掉p.join()，代码执行逻辑如下所述：</p><p>　　父进程执行到p.start()后，子父进程开始同时执行；当父进程结束后，子进程继续执行；此时父进程并不退出依然存在，且进程状态依然为休眠状态(S+)；当子进程结束后，子父进程同时销毁。打印结果如下图所示：</p><p><img src="./子进程运行周期长，且不调用join.png" alt="子进程运行周期长，且不调用join"></p><h3 id="子进程调用join-方法：无僵尸进程存在"><a href="#子进程调用join-方法：无僵尸进程存在" class="headerlink" title="子进程调用join()方法：无僵尸进程存在"></a>子进程调用join()方法：无僵尸进程存在</h3><p>取消p.join()的注释，代码执行逻辑如下所述：</p><p>　　首先启动父进程，当执行到p.start()后，子进程开始执行，此时父进程处于挂起状态；当子进程结束后，父进程开始继续执行后续代码。打印结果如下图所示：</p><p><img src="./子进程运行周期长，调用无参join.png" alt="子进程运行周期长，调用无参join"></p><h2 id="场景二：子进程运行周期小与父进程"><a href="#场景二：子进程运行周期小与父进程" class="headerlink" title="场景二：子进程运行周期小与父进程"></a>场景二：子进程运行周期小与父进程</h2><h3 id="子进程不调用join-方法：有僵尸进程存在"><a href="#子进程不调用join-方法：有僵尸进程存在" class="headerlink" title="子进程不调用join()方法：有僵尸进程存在"></a>子进程不调用join()方法：<font color="red">有僵尸进程存在</font></h3><p>修改main_process_time为30，child_process_time为10；并注释掉p.join()，代码执行逻辑如下所述：</p><p>　　首先启动父进程，当执行到p.start()后，子父进程开始同时执行；<font color="red">当子进程尚未结束时</font>，子父进程的打印结果及其进程状态如下图所示：</p><p><img src="./父进程运行周期长，不调用join，且子进程尚未结束.png" alt="父进程运行周期长，不调用join，且子进程尚未结束"></p><p><font color="red">当子进程结束，但父进程尚未结束时，子进程变为僵尸进程</font>，进程的打印结果和进程状态如下图所示：</p><p><img src="./父进程运行周期长，不调用join，且子进程已经结束.png" alt="父进程运行周期长，不调用join，且子进程已经结束"></p><h3 id="子进程调用join-方法：无僵尸进程存在-1"><a href="#子进程调用join-方法：无僵尸进程存在-1" class="headerlink" title="子进程调用join()方法：无僵尸进程存在"></a>子进程调用join()方法：无僵尸进程存在</h3><p>修改main_process_time为30，child_process_time为10；并取消p.join()的注释，代码执行逻辑如下所述：</p><p>　　当父进程执行到p.start()后，子进程开始执行，且父进程挂起；当子进程尚未结束时，程序打印结果以及系统中进程状态如下图所示：</p><p><img src="./父进程运行周期长，调用无参join，且子进程尚未结束.png" alt="父进程运行周期长，调用无参join，且子进程尚未结束"></p><p><font color="red">当子进程结束而父进程尚未结束时，子进程正常销毁</font>，此时只有父进程在继续运行;程序打印结果以及系统中进程状态如下图所示：</p><p><img src="/images/placeholder.png" alt="父进程运行周期长，调用无参join，且子进程已经结束" data-src="./父进程运行周期长，调用无参join，且子进程已经结束.png" class="lazyload"></p><h2 id="子父进程伪并发"><a href="#子父进程伪并发" class="headerlink" title="子父进程伪并发"></a>子父进程伪并发</h2><p>　　在写代码的时候，需要注意join()方法位置；否则有可能会导致看似的多进程并发代码，实则的多进程的串行执行。Eg：将样例代码中的MainProcess类的excutor方法改写成如下形式：</p><p><img src="/images/placeholder.png" alt="join串行代码写法" data-src="./join串行代码写法.png" class="lazyload"></p><p>　　当基于for循环创建子进程时，若将p.join()卸载循环体内，则实际的执行逻辑为：主线程 =&gt; 子线程1 =&gt; 子线程2 =&gt; 子线程3 =&gt; 主线程；代码打印结果如下图所示：</p><p><img src="/images/placeholder.png" alt="join串行代码输出结果" data-src="./join串行代码输出结果.png" class="lazyload"></p><p>　　若想基于该写法实现真并发，可将p.join()改写为p.join(0.001)即可；代表着新建子进程后父进程的挂起时间仅为0.001秒，因此可以近似等价于同时执行；执行效果如下图所示：</p><p><img src="/images/placeholder.png" alt="join并行输出结果" data-src="./join并行输出结果.png" class="lazyload"></p><p>不过不建议采用这样的写法，因为这样会产生僵尸进程(详见<a href="https://yhyr.github.io/2018/06/06/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%BA%8C/" target="_blank" rel="noopener">join详解</a>)。</p><h1 id="Linux进程基本概念"><a href="#Linux进程基本概念" class="headerlink" title="Linux进程基本概念"></a>Linux进程基本概念</h1><p>　　在Linux中，默认情况下当父进程创建完子进程后，子父进程的运行是相互独立的、异步的；即父进程无法感知到子进程何时结束。为了让父进程可以在任意时刻都能获取到子进程结束时的状态信息，提供了如下机制：</p><ul><li>1) 当子进程结束后，系统在释放该子进程的所有资源的同时(eg：占用的内存、打开的文件等)，仍会保留一定的信息，包括进程号(process id)，进程的退出状态(the termination status of the process)，运行时间(the amount of CPU time taken by the process)等。</li><li>2) 当父进程调用wait/waitpid方法获取子进程的退出状态信息后，系统会彻底释放掉对应子进程的所有信息。如果父进程没有调用wait/waitpid方法，且父进程一直存活，则该子进程所有用的端口号信息一直保存，从而该子进程变为僵尸进程(对系统有害)；若父进程没有调用wait/waitpid方法，且父进程已经结束，则子进程会从僵尸进程转变为孤儿进程(对系统无害)。</li></ul><h3 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h3><p>　　一个进程创建了一个子进程，且当该子进程结束后，父进程没有调用wait/waitpid方法来获取子进程的退出状态信息，那么该子进程将会一直保留在系统中，并持续占有该进程的端口号等信息；进程标识符为<code>&lt;defunct&gt;</code>，进程状态位为Z，这种进程称之为僵尸进程。如下图所示：</p><p><img src="/images/placeholder.png" alt="僵尸进程" data-src="./僵尸进程.png" class="lazyload"></p><h3 id="孤儿进程"><a href="#孤儿进程" class="headerlink" title="孤儿进程"></a>孤儿进程</h3><p>　　当父进程退出而子进程还在运行时，这些子进程将会变成孤儿进程。孤儿进程将会init进程统一管理。因为init进程的进程号为1，所以所有的孤儿进程的父进程号均为1；此外，因为init进程会主动收集所有子进程的退出状态信息，所有由init进程管理的子进程是不会变成僵尸进程。因此，孤儿进程是对系统无害的。</p><p>　　例如：在上述样例代码的基础上，将子父进程的运行周期均扩大为60(保证有足够的时间去手动kill掉父进程，方便举例验证)，当子父进程运行的同时，手动kill掉父进程，子进程的进程号变化如下图所示</p><p>kill前：</p><p><img src="/images/placeholder.png" alt="孤儿进程手动kill前" data-src="./孤儿进程手动kill前.png" class="lazyload"></p><p>kill后：</p><p><img src="/images/placeholder.png" alt="孤儿进程手动kill后" data-src="./孤儿进程手动kill后.png" class="lazyload"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>　　Linux中，如果父进程正常结束的同时，子进程还未结束，此时父进程并不会退出让子进程变成孤儿进程，而是会有一个等待的操作；以阻塞或者轮询的方式等待所有子进程的结束而结束，毕竟“爸爸管儿子是天经地义的事”；正因为如此，在该应用场景一下(子进程的运行周期大于父进程)，即使不调用join()方法，也不会存在僵尸进程。如果在父进程在执行过程中因为调用os.exit()或者外部直接kill掉，此处父进程就不会在管理自己所产生的子进程，从而会导致子进程变成孤儿进程。相反如果子进程结束时父进程还未结束，此时如果未调用join()方法，则会因为父进程没有获取并处理子进程的退出信息而导致子进程变成僵尸进程；如果父进程一直存在，则该僵尸进程也会一直存在，相反如果父进程结束，则父进程在结束的前会等待并清除自己所产生的所有子进程的退出信息，从而消除僵尸进程。</p><p>　　通过上述demo，可以看出在不加join的时候，子父进程的运行方式是一种真正意义上的并行，但是由于特定的场景会导致出现僵尸进程；而加了join后，可以有效的消除僵尸进程，但是所写的多进程代码实则是一种多进程的串行执行模式(即：父进程会等待子进程结束后在执行)，其实是因为join()方法本身就是一种以阻塞主进程来等待子进程的方法。关于join()的解释和切实有效的消除僵尸进程可详见<a href="https://yhyr.github.io/2018/06/06/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%BA%8C/" target="_blank" rel="noopener">传送门</a></p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> 多进程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于Python初探Linux下的僵尸进程和孤儿进程(二)</title>
      <link href="/2018/06/06/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%BA%8C/"/>
      <content type="html"><![CDATA[<p>了解Python-Process的join()方法的含义、以及在解决僵尸进程的原理和不足；同时结合实际应用场景提出有效可行的消除僵尸进程的方案。</p><a id="more"></a><h1 id="multiprocessing-Process的join-方法"><a href="#multiprocessing-Process的join-方法" class="headerlink" title="multiprocessing.Process的join()方法"></a>multiprocessing.Process的join()方法</h1><p>　　通过<a href="https://yhyr.github.io/2018/06/07/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%B8%80/" target="_blank" rel="noopener">上篇博文</a>可以看出join()方法具有清除僵尸进程的作用，与此同时带来的负面作用就是子父进程的串行执行(此处假设我们的目标是保证子父进程的执行方式是非阻塞的；对于实际需求是需要父进程阻塞等待子进程结束后在执行的应用场景，可以忽略本篇博文)。接下来将从join的底层实现出发探究其能够清楚僵尸进程的原因和阻塞执行的方式；同时基于一个demo来给出实际工作中如何准确有效的避免和消除僵尸进程。</p><h2 id="join初探"><a href="#join初探" class="headerlink" title="join初探"></a>join初探</h2><p><img src="./join源码描述.png" alt="join源码描述"></p><p>　　基于PyCharm查看join的源码，如上图所示；官方描述该方法的功能是“等待，直到子进程结束”；从字面意思也不难看出，该方法是一个阻塞方法；需要注意的是这里<strong>等待的主语是主进程而非子进程</strong>。该方法主要做了两件事：</p><ol><li>(1) 通知父进程调用wait方法</li><li>(2) 将该子进程从父进程的子进程列表中移除</li></ol><p>　　第一件事调用wait方法背后的实际调用链是：process模块的Process.join()  =&gt; forking模块的Popen.wait()，实则是调用了os.waitpd方法【注意这里的Popen根据操作系统的不同而不同，分为Unix/Linux和Windows两种】；至于为什么要调用该方法可以看我<a href="https://yhyr.github.io/2018/06/07/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%B8%80/" target="_blank" rel="noopener">上篇博文</a>中有关Linux进程基本概念模块的描述。</p><p><img src="./join底层调用.png" alt="join底层调用"></p><p>　　看到这，对于join()能消除僵尸进程的原因应该有了较为深刻的认识了；但是还存在一个问题：进程的串行执行问题还未解决。源码中join有一个timeout的参数，该参数的作用是设置一个该方法调用的等待时间，如果不设置，则等待子进程结束后在执行父进程；如果设置了，当子进程的运行周期大于你所设置的timeout时长时，表示过了timeout时长后(单位是秒)，开始唤醒父进程，此时子父进程开始同时执行；如果子进程的运行周期小与你所设置的timeout时长时，当你的子进程结束后会立即执行父进程，而不用等待你所设置的时长结束后才开始唤醒父进程。光说这些理论可能印象不会太深刻，接下来用几组例子来抛砖引玉，在加深对join理解的同时，介绍两种僵尸进程的有效清除办法。</p><p>样例代码如下所示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, main_process_time, child_process_time)</span>:</span></span><br><span class="line">        self.main_process_time = main_process_time</span><br><span class="line">        self.child_process_time = child_process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        p = ChildProcess(self.child_process_time)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join(<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.main_process_time):</span><br><span class="line">            print(<span class="string">'main process, pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.process_time):</span><br><span class="line">            print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'child process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main_process_time = <span class="number">15</span></span><br><span class="line">    child_process_time = <span class="number">10</span></span><br><span class="line">    action = MainProcess(main_process_time, child_process_time)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure><h2 id="场景一：子进程的运行周期大于父进程"><a href="#场景一：子进程的运行周期大于父进程" class="headerlink" title="场景一：子进程的运行周期大于父进程"></a>场景一：子进程的运行周期大于父进程</h2><p>　　在该应用场景下，无论是否调用join方法都不会有僵尸进程存在；如果调用join，则父进程会被挂起，子父进程串行执行；如果不调用join，子父进程并行执行；现在分析一下调用带参数的join方法(eg：p.join(3))，当父进程启动，子进程执行时间小于三秒时，执行效果如下图所示：</p><p><img src="./子进程周期大于父进程,join带参数且子进程运行时间小于三秒.png" alt="子进程周期大于父进程,join带参数且子进程运行时间小于三秒"></p><p>当子进程执行时间大于三秒且小于父进程的执行周期时，执行效果如下图所示：</p><p><img src="./子进程周期大于父进程,join带参数且子进程运行时间大于三秒小于父进程周期.png" alt="子进程周期大于父进程,join带参数且子进程运行时间大于三秒小于父进程周期"></p><p>当父进程结束，而子进程继续执行，程序输出结果如下图所示：</p><p><img src="./子进程周期大于父进程,join带参数且父进程结束.png" alt="子进程周期大于父进程,join带参数且父进程结束"></p><h2 id="场景二：子进程的运行周期小与父进程"><a href="#场景二：子进程的运行周期小与父进程" class="headerlink" title="场景二：子进程的运行周期小与父进程"></a>场景二：子进程的运行周期小与父进程</h2><p>　　在该应用场景下，如果不调用join，则会有僵尸进程产生；如果调用join，则可以消除僵尸进程，但是子父进程串行执行；这种结果也并非我们所需要的。接下来尝试一下调用带参数的join方法(eg：p.join(3))，修改上述样例代码将main_process_time设置为15，child_process_time设置为10：</p><p>当父进程启动，子进程执行时间小于三秒时，执行效果如下图所示：</p><p><img src="/images/placeholder.png" alt="子进程周期小与父进程，join带参数且子进程执行时间小于三秒" data-src="./子进程周期小与父进程，join带参数且子进程执行时间小于三秒.png" class="lazyload"></p><p>当子进程执行时间大于三秒且小于子进程的执行周期时，执行效果如下图所示：</p><p><img src="/images/placeholder.png" alt="子进程周期小与父进程，join带参数且子进程执行时间大于三秒且小于子进程周期" data-src="./子进程周期小与父进程，join带参数且子进程执行时间大于三秒且小于子进程周期.png" class="lazyload"></p><p>当子进程结束，父进程继续执行时，程序输出结果如下图所示：</p><p><img src="/images/placeholder.png" alt="子进程周期小与父进程，join带参数且子进程结束" data-src="./子进程周期小与父进程，join带参数且子进程结束.png" class="lazyload"></p><p>　　通过这个例子可以看出，在该应用场景下，<font color="red">不论是加了带参数的join还是不加join，都会有僵尸进程产生</font>；相反加了不带参数的join虽可以避免僵尸进程，但是由于子父进程的串行执行导致仍无法满足我们的需求；为什么带参数和不带参数的join执行效果会如此大相径庭呢？其实通过上述源码是可以看出，<strong>join方法确实是会调用系统的os.waitpid()方法来获取子进程的退出信息，从而达到消除子进程的目的；但是这个过程是一次性的</strong>。什么意思呢？就是如果不带参数，则会一直挂起父进程，直到子进程结束后再执行p.join()方法，从而清除子进程；相反如果带参数，则会挂起父进程timeout时长后，唤醒父进程，此时父进程首先会执行p.join(3)这行代码，如果当前时刻子进程还未结束，则p.join(3)获取子进程的退出状态信息为空，则不会清除子进程，然后会紧接着执行父进程的后续逻辑；这时子父进程开始并行执行。如果子进程在次之后结束的同时父进程还未结束，则父进程会因为无法获取到子进程的退出信息而导致子进程沦为僵尸进程。(开始自己以为join(3)意味着父进程会在三秒后唤醒的同时，父进程会轮询监控子进程的退出信息，从而达到消除僵尸进程的作用，^v^ 还是太年轻~想当然了~哈哈！！！)。</p><h1 id="消除僵尸进程"><a href="#消除僵尸进程" class="headerlink" title="消除僵尸进程"></a>消除僵尸进程</h1><p>　　随着对Process的join()方法的深入理解，越发觉得离我们的目标渐行渐远。要不就会产生僵尸进程，要不就会挂起父进程，从而无法实现并行效果。那么问题来了，到底该如何有效的消除僵尸进程呢？</p><p>　　网上有些帖子和博客说可以通过os._exti(0)或者sys.exit(0)可以有效的退出子进程，这一点毋庸置疑；但是需要注意的是这种退出并没有什么太大的作用，因为主动退出子进程并不会通知父进程去获取子进程得退出状态信息，从而导致子进程还是会变成僵尸进程。在这里我将介绍两种行之有效的方法来实现彻底消除僵尸进程的同时，实现子父进程的并发。</p><h2 id="方法一：创建两次子进程-fork两次"><a href="#方法一：创建两次子进程-fork两次" class="headerlink" title="方法一：创建两次子进程(fork两次)"></a>方法一：创建两次子进程(fork两次)</h2><p>　　如果百度过此类问题的不难发现，网上有很多说可以通过fork两次来避免僵尸进程。其实这是一个很不错的方法，也是一个比较容易理解的。只是关于该方法的解释不是很多(可能因为笔者太low，对于很多人来说都是一看就懂的^v^)，在这里我将就该方法做以详细的解释和说明，希望对刚接触此类问题的小伙伴们有所帮助。</p><p>　　首先需要注意的是fork函数是unix/linux系统上特有的，在Windows上运行该函数会直接报错，而通过都是用Windows机器做开发，在Linux上跑代码的这种，直接在Linux上写代码又是比较麻烦的(如果愿意可以基于VM搭建一个桌面版的CentOS，然后装个编译器来开发)，所以这里笔者从一开始就选择Python提供的一种跨平台的多进程模块 – multiprocessing来实现多进程(其实multiprocessing中基于Linux的代码实现逻辑就是fork，对于该模块源码初探可详见<a href="https://yhyr.github.io/2018/06/07/%E5%9F%BA%E4%BA%8EPython%E5%88%9D%E6%8E%A2Linux%E4%B8%8B%E7%9A%84%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B-%E4%B8%89/" target="_blank" rel="noopener">传送门</a>)。</p><p>　　如何理解fork两次即可达到我们想要的想过呢？此处假设我们的业务场景是父进程一直存在，而子进程的执行周期短，且执行完后就退出。我们知道，当主进程创建一个子进程时，此时子进程的ppid即就是父进程的pid；而子进程结束后如果父进程没有获取子进程的退出状态信息，则子进程会变成僵尸进程；我们又知道，如果一个子进程是孤儿进程的话，那么它就是安全可靠的(不会产生僵尸进程)；所以基于以上原因，可以进行如下设计：主进程的业务逻辑保持不变，只是在主进程创建子进程的时候，不直接创建子进程去执行相应的业务逻辑；而是创建一个单独进程(此处理解为爸爸进程)，该进程只干一件事，就是创建原本应该有父进程创建的子进程。即就是<font color="red">将原本的“主进程 =&gt; 儿子进程”修改为“主进程 =&gt; 爸爸进程 =&gt; 儿子进程”</font>，这种设计里只有主进程和儿子进程是需要关注的，而爸爸进程逻辑很简单，就是初始化儿子进程；所以当爸爸进程结束后儿子进程就沦为孤儿进程了，这样无论儿子进程执行多久，都不会产生僵尸进程。</p><p>　　有人就会想，爸爸进程退出不也会产生僵尸进程吗？其实这个问题很好解决，利用上述中的不带参数的join()方法即可解决。可以在主进程中创建父进程的同时，添加p.join()方法，因为爸爸进程创建儿子进程的耗时很短，所以可以在主进程创建爸爸进程的时候使用p.join()挂起，这个时间差是可以忽略和接受的，这样当父进程创建完儿子进程后父进程就会立马结束，此时主进程就会执行p.join()方法获取到爸爸进程的退出信息，从而彻底消除爸爸进程；这样进程列表里就只剩下一个主进程和一个而孤儿进程(原本的儿子进程转化而来)；这样就实现了真正意义上的并发。为了测试时效果看的明显，在源码中添加了sleep()，如果在实际的业务开发中，可以注掉源码中的相关sleep()代码，具体源码如下所示(该写法可兼容Windows和Linux)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, main_process_time, child_process_time)</span>:</span></span><br><span class="line">        self.main_process_time = main_process_time</span><br><span class="line">        self.child_process_time = child_process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process begin, pid=&#123;0&#125;'</span>.format(os.getpid()))</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        p = FatherProcess(self.child_process_time)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.main_process_time):</span><br><span class="line">            print(<span class="string">'main process, pid=&#123;0&#125;, times=&#123;1&#125;'</span>.format(os.getpid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'main process end, pid=&#123;0&#125;'</span>.format(os.getpid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FatherProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'father process begin, pid=&#123;&#125; =&gt; create childPorcess'</span>.format(os.getpid()))</span><br><span class="line">        p = ChildProcess(self.process_time)</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        p.start()</span><br><span class="line">        print(<span class="string">'father process end, pid=&#123;&#125;'</span>.format(os.getpid()))</span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">        os._exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process begin, pid=&#123;0&#125;'</span>.format(os.getpid()))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.process_time):</span><br><span class="line">            print(<span class="string">'child process pid=&#123;0&#125;, times=&#123;1&#125;'</span>.format(os.getpid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'child process end, pid=&#123;0&#125;'</span>.format(os.getpid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main_process_time = <span class="number">10</span></span><br><span class="line">    child_process_time = <span class="number">5</span></span><br><span class="line">    action = MainProcess(main_process_time, child_process_time)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure><h2 id="方法二：基于Linux信号清除僵尸进程"><a href="#方法二：基于Linux信号清除僵尸进程" class="headerlink" title="方法二：基于Linux信号清除僵尸进程"></a>方法二：基于Linux信号清除僵尸进程</h2><p>　　创建两次子进程的方法是比较好理解的，但是代码的入侵还是比较大的，基于Linux信号的方式可以只需要添加一行代码<code>signal.signal(signal.SIGCHLD, signal.SIG_IGN)</code>就可实现所需要的逻辑；不过该解决方案只适用于Linux/Unix系统；在Windows下执行是会报错。代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> signal</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainProcess</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, main_process_time, child_process_time)</span>:</span></span><br><span class="line">        self.main_process_time = main_process_time</span><br><span class="line">        self.child_process_time = child_process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">excutor</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'main process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        添加信号</span></span><br><span class="line"><span class="string">            signal.SIGCHLD的语义为：子进程状态改变后产生此信号</span></span><br><span class="line"><span class="string">            signal.SIG_IGN的语义为：信号的处理方式为忽略模式</span></span><br><span class="line"><span class="string">            默认采用SIG_DFL, 代表默认的处理方式为不会理会这个信号，但是也不会丢弃该信号量，</span></span><br><span class="line"><span class="string">            如果系统不调用wait/waitpid，则会变成僵尸进程</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">            第二个参数也可以自定义处理逻辑，eg：将signal.SIG_IGN修改为自定义sigchld_handler方法，</span></span><br><span class="line"><span class="string">            专门用来处理对应的信号</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        signal.signal(signal.SIGCHLD, signal.SIG_IGN)</span><br><span class="line"></span><br><span class="line">        p = ChildProcess(self.child_process_time)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join(<span class="number">5</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.main_process_time):</span><br><span class="line">            print(<span class="string">'main process, pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChildProcess</span><span class="params">(multiprocessing.Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, process_time)</span>:</span></span><br><span class="line">        multiprocessing.Process.__init__(self)</span><br><span class="line">        self.process_time = process_time</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'child process begin, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.process_time):</span><br><span class="line">            print(<span class="string">'child process pid=&#123;0&#125;, ppid=&#123;1&#125;, times=&#123;2&#125;'</span>.format(os.getpid(), os.getppid(), i))</span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">'child process end, pid=&#123;0&#125;, ppid=&#123;1&#125;'</span>.format(os.getpid(), os.getppid()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main_process_time = <span class="number">30</span></span><br><span class="line">    child_process_time = <span class="number">15</span></span><br><span class="line">    action = MainProcess(main_process_time, child_process_time)</span><br><span class="line">    action.excutor()</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> 多进程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python-Mysql依赖初探</title>
      <link href="/2018/06/01/Python-Mysql%E4%BE%9D%E8%B5%96%E5%88%9D%E6%8E%A2/"/>
      <content type="html"><![CDATA[<h3 id="环境依赖"><a href="#环境依赖" class="headerlink" title="环境依赖"></a>环境依赖</h3><blockquote><p>MySQL 5.7.17</p><p>Python 2.7</p><p>Mysql-python 1.2.5</p></blockquote><a id="more"></a><p>　　MySQLdb是基于MySQL C API(原生MySQL API)为核心的面向Python的接口，封装了许多MySQL C API的方法，简化Python操作MySQL的难度。在原生的MySQL API中，万物皆String。(当然，可以通过自定义conv来实现数据类型的转化)。官方解释如下图所示：</p><p><img src="./mysqldb_官方解释.png" alt="mysqldb_官方解释"></p><p>　　Eg：原始的数据源中，age列是int类型，基于原生API查询后，所有的结果均为String类型；执行效果如下图所示：</p><p><img src="./mysql原生写法.png" alt="mysql原生写法"></p><p>　　可以通过自定义转换dict来实现查询结果的类型转换；具体的实现也很简单，只需要在mysql初始化的时候，自定义conv参数即可(eg：将SQL中int转化为Long，将SQL中的float转化为Double)，样例代码如下图所示：</p><p><img src="./mysql原生写法_自定义conv参数.png" alt="mysql原生写法_自定义conv参数"></p><p>　　由于原始API并不是那么的拿来主义，直接基于此操作需要care的东西太多，所以才有了MySQLdb这样简单易上手的第三方依赖包。MySQLdb带来的便捷主要体现在一下两点：</p><ol><li>封装并提供很多API接口，降低使用门槛</li><li>自动适配原始SQL表的字段类型</li></ol><p>　　由于高级的API方法在实际工作中以用到很多，并且和其他语言的mysql驱动没太大差别，在这里不做讨论。重点分享一下第二点，在数据类型自定识别中，存在如下一种情况：<strong>基于MySQLdb查询int字段时，实际默认的返回类型是Long型，而非int</strong>。 Eg：</p><p><img src="./mysqldb写法.png" alt="mysqldb写法"></p><p>　　官方给出的解释是：<em>while MySQL’s INTEGER column translates perfectly into a Python integer, UNSIGNED INTEGER could overflow, so these values are converted to Python long integers instead</em>. 简单的说，就是<strong>MySQL的int类型转化为Python的int类型时，可能存在无符号整形精度丢失的情况</strong>。如何理解这句话：通过在程序中(Python)，不会刻意的定义一个无符号的整形变量，一般默认的int为有符号整形，eg：假如为int32，则对应的有符号整形的范围为：-2^(32-1) ~ 2^(32-1) - 1；相反无符号整数的范围为：0 ~ 2^32 - 1；所以当数据可中指定int为无符号整型时，程序中用有符号整形接受，就会存在因为数据范围不一致而导致的数据精度丢失情况。基于此原因，MySQLdb在设计时，为了规避该潜在问题，默认将int类型转化为long型。这就是为什么整形查询结果后面会带有L后缀的原因。</p><p>　　当然MySQLdb也可以支持类似原生API那种通过自定义conv参数的方式来实现数据类型的自定义(不过不建议用户这样操作)。Eg：将SQL中Long转化为int，将SQL中的double转化为flout，代码样例如下图所示：</p><p><img src="./mysqldb自定conv参数.png" alt="mysqldb自定conv参数"></p><p>　　因为MySQLdb对应所有的mysql数据类型都有一套自己默认的转化映射关系(详见源码：MySQLdb.converters)，对于原生API，可以指定自己想转化的特定数据列；但是该方法在MySQLdb中并不那么的适用；如果要自定义数据类型，就必须指定所涵盖的所有数据列，这样很有可能因为枚举不够全面而导致程序报错的情况；所以在实际工作时，不建议在这一步转化数据类型，如有需要，在将数据加载到内存后，再转化成所需要的类型。</p><p>参考链接：<a href="http://mysql-python.sourceforge.net/MySQLdb.html" target="_blank" rel="noopener">官方Doc</a> </p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> MySQL </tag>
            
            <tag> MySQLdb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于pandas的数据分析之数据类型转化踩坑总结</title>
      <link href="/2018/06/01/%E5%9F%BA%E4%BA%8Epandas%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96%E8%B8%A9%E5%9D%91%E6%80%BB%E7%BB%93/"/>
      <content type="html"><![CDATA[<h3 id="从以下两个方面来讨论在实际工作中所遇到的数据类型转化问题"><a href="#从以下两个方面来讨论在实际工作中所遇到的数据类型转化问题" class="headerlink" title="从以下两个方面来讨论在实际工作中所遇到的数据类型转化问题"></a>从以下两个方面来讨论在实际工作中所遇到的数据类型转化问题</h3><ol><li>由于数据缺失导致DataFrame中int转float</li><li>由于数据类型字符串导致csv加载到DataFrame时String转numeric</li></ol><a id="more"></a><h3 id="环境依赖"><a href="#环境依赖" class="headerlink" title="环境依赖"></a>环境依赖</h3><blockquote><p>MySQL 5.7.17</p><p>Python 2.7</p><p>MySQL-python 1.2.5</p><p>Pandas 0.18.1</p></blockquote><h1 id="一、由于数据缺失导致DataFrame中int转float"><a href="#一、由于数据缺失导致DataFrame中int转float" class="headerlink" title="一、由于数据缺失导致DataFrame中int转float"></a>一、由于数据缺失导致DataFrame中int转float</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>将MySQL的表结构转为Pandas的DataFrame时，会出现如下问题：</p><ul><li>age列原本为int类型，但是在DataFrame中转化为float类型</li><li>对于SQL中的None值，在DataFrame里有多种表示方式</li></ul><p>数据源信息如下所示：</p><p><img src="./表数据信息.png" alt="表数据信息"></p><p><img src="./表字段信息.png" alt="表字段信息"></p><p><img src="./表信息在DataFrame中的展示效果.png" alt="表信息在DataFrame中的展示效果"></p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>　　通过查阅官方文档得知，pandas在处理缺失值上，拥有一套自己的转化逻辑；具体的转化规则如下图所示：</p><p><img src="./pandas缺失值处理规则.png" alt="pandas缺失值处理规则"></p><p>　　不难看出，当int型数据列包含空值时，会将该列转化为float类型；个人理解：在pandas中，对于数据类型的空值，是统一用Nan来表示的；Nan在pandas中是一float类型，代表一种特殊的值，而非其他语言中所定义的空对象；因此对于int类型的空值，因无法表示相应的空值，所以需要先做数据类型的转化，然后用Nan来表示其含义。</p><p><img src="./Python_nan值类型.png" alt="Python_nan值类型"></p><p>　　通过这个例子，希望在理解numeric类型转化原因的同时，能够提高对异常数据的警惕性和敏感度；理解业务，实现需求的同时，能有准确、有效的进行数据降噪，从而提升数据的真实性和可信度。</p><h1 id="由于数值类型字符串导致从csv加载到DataFrame时String转numeric"><a href="#由于数值类型字符串导致从csv加载到DataFrame时String转numeric" class="headerlink" title="由于数值类型字符串导致从csv加载到DataFrame时String转numeric"></a>由于数值类型字符串导致从csv加载到DataFrame时String转numeric</h1><h2 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h2><p>缺失值分别在MySQL、Python和Pandas上的表现形式如下所示：</p><table><thead><tr><th>/</th><th>字符串空值</th><th>空字符串</th><th>数值类型空值</th></tr></thead><tbody><tr><td>MySQL</td><td>Null</td><td>‘’</td><td>Null</td></tr><tr><td>Python</td><td>None</td><td>‘’</td><td>None</td></tr><tr><td>Pandas</td><td>None</td><td>‘’</td><td>Nan</td></tr></tbody></table><p>　　<strong>由于字符串空值和空字符串这两种情况在写到csv的效果完全一致，从而导致在读取数据时无法做区分</strong>。如果后续业务明确要求区分处理这两种情况，则会因为一次文件的读写操作导致数据失真。基于此原因，建议在实际开发的过程中，在同一个team下规定一个唯一的字符串标识符来代表None值(参考数仓建设)，从而有效区分字符串空值和空字符串的区别。</p><h2 id="数据类型转化"><a href="#数据类型转化" class="headerlink" title="数据类型转化"></a>数据类型转化</h2><p>　　通过pd.read_csv方法加载csv文件时，如果某一列为数值字符串，则该列会别识别为numeric类型(eg：int, float)，而非原始的String类型。Eg：将前文中MySQL数据表中的sex列和passWord列的内容修改为纯数值，数据集及各列对应的数据类型分别如下所示：</p><p><img src="/images/placeholder.png" alt="数值型字符串数据集" data-src="./数值型字符串数据集.png" class="lazyload"></p><p><img src="/images/placeholder.png" alt="原始数据集数据类型" data-src="./原始数据集数据类型.png" class="lazyload"></p><p>　　并将该表中的数据先写到本地csv文件；然后通过pd.read_csv读取文件时发现sex列被识别为int类型，passWord列被识别为float类型。数据展示效果及各列对应的数据类型分别如下图所示：</p><p><img src="/images/placeholder.png" alt="经过一次读写操作后的数据集" data-src="./经过一次读写操作后的数据集.png" class="lazyload"></p><p><img src="/images/placeholder.png" alt="经过一次读写操作后的数据集数据类型" data-src="./经过一次读写操作后的数据集数据类型.png" class="lazyload"></p><p>　　所以在基于pandas操作csv文件时，需要特别注意这种情况。如果在后续的分析中，需要保留原始数据格式，则在读取csv文件时，需要通过dtype参数来显示的指定目标字段的数据类型，从而保证数据类型的前后统一。</p><p><img src="/images/placeholder.png" alt="读csv指定数据类型" data-src="./读csv指定数据类型.png" class="lazyload"></p><p><img src="/images/placeholder.png" alt="指定读取类型后的字段数据类型" data-src="./指定读取类型后的字段数据类型.png" class="lazyload"></p><p>　　通过上述案例分析，希望今后在操作csv文件时注意区分空字符串和字符串空值在不同应用场景下的实际意义，以免造成潜在的数据隐患。</p>]]></content>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基于GitHub Pages + Hexo 多端搭建本地博客环境</title>
      <link href="/2018/05/28/%E5%9F%BA%E4%BA%8EGitHub-Pages-Hexo-%E5%A4%9A%E7%AB%AF%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E5%8D%9A%E5%AE%A2%E7%8E%AF%E5%A2%83/"/>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>阅读此文前，假定你已经了解如何基于GitHub Pages + Hexo来搭建个人博客。如果不了解的，可参考如下<a href="https://www.cnblogs.com/fengxiongZz/p/7707219.html" target="_blank" rel="noopener">教程</a>或<a href="http://crazymilk.github.io/2015/12/28/GitHub-Pages-Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/" target="_blank" rel="noopener">教程</a>(就不重复造轮子了)；为自己的博客添加主题，其实也很简单：只需要在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">Hexo</a>中挑选出自己心仪的风格，并将对应的源码从GitHub上clone到本地，并存放在你本地博客目录的themes路径下，并修改博客根目录的_config.yml文件，将theme: landscape中的landscape替换为你clone下来的文件夹名即可。具体操作参考<a href="http://www.cnblogs.com/fengxiongZz/p/7707568.html" target="_blank" rel="noopener">教程</a>。</p><a id="more"></a><p>接下来进入正题：搭建过个人博客的都清楚，Hexo是通过Node.js将本地的md文件(即就是你的博客源文件)基于指定的主题渲染成静态页面，在本地生成public文件夹，然后通过部署将public文件夹同步到GitHub上，这样你就可以通过username.github.io来访问。那么问题来了，当你如果换了台电脑或者想在其他机器上修改你的博客或者写一篇新博客，这就没招了。因为通过Hexo发布到GitHub上的是经过Node.js渲染过后的HTML文件，而非原始的md文件；所有你clone下GitHub上的源码也没什么用，除非你可以接受直接基于HTML写文档，那在这里我给你一个大写的服字。</p><h2 id="Hexo的安装过程"><a href="#Hexo的安装过程" class="headerlink" title="Hexo的安装过程"></a>Hexo的安装过程</h2><p>首先，通过<code>npm install hexo -g</code>在本地安装hexo(保证电脑上已经安装了git和node.js)</p><p>然后，在指定路径下执行<code>hexo init</code>命令来初始化hexo环境的相关文件，结果如下图所示：</p><p><img src="./hexo_init.png" alt="hexo初始化目录列表"></p><p>初始化出来的文件均为hexo环境配置</p><p>其次，通过<code>npm install</code>命令安装相关依赖，再通过<code>hexo g</code>来实现文档渲染，最后通过<code>hexo s</code>开始本地服务，如果报端口占用，可通过<code>hexo s -p 5000</code>重定向端口号，就可以通过localhost:5000来实现本地模式查看。当通过<code>hexo g</code>渲染文档后，会发现在博客根目录下新建了一个public目录，如下图所示：</p><p><img src="./hexo_g.png" alt="hexo渲染目录结构"></p><p>public目录就是最终发布到GitHub上的目录，node_module目录是执行完<code>npm install</code>后安装在本地的相关依赖，不用care它。</p><p>在理解了hexo的目录结构以后不难看出，其实博客网站只关注public目录；而hexo的环境信息(所使用的主题、所有博客的原md格式的文档、博客的配置信息)都是在scaffolds，source，themes和_config.yml中，所以只需要将这些文件维护到GitHub上，就可以随时随地在任何地方down下自己的环境文件，从而就可以开始你的创作了。</p><h2 id="实现方案"><a href="#实现方案" class="headerlink" title="实现方案"></a>实现方案</h2><p>在username.github.io仓库中新建一个hexo分支，用master分支来存放hexo发布的静态网页信息(即就是public目录下的内容)，用hexo分支来存放你的博客环境信息。其实当你执行完<code>hexo init</code>初始化命令后，你会发现hexo会默认帮你生成一个.gitignore文件，内容如下所示：</p><p><img src="./hexo_init_gitignore.png" alt="gitignore内容"></p><p>这里面已经自动帮你剔除了所有和hexo环境信息无关的目录了，所有你不做主动做任何过滤，直接在本地新建一个hexo分支，并将环境信息提交到GitHub对应的hexo分支即可。在博客根目录的_config.yml中指定deploy的branch为master分支即可。</p><h2 id="本地自测"><a href="#本地自测" class="headerlink" title="本地自测"></a>本地自测</h2><p>在本机新建一个文件夹，将username.github.io仓库的hexo分支clone到本地，然后执行<code>npm install</code>命令来安装所需要的相关相关依赖。<strong>切结不要执行<code>hexo init</code>命令</strong> ，因为该命令会初始化本地hexo环境，会用默认的hexo配置和主题来覆盖你自己的设置；因为我们hexo分支上的源码已经是自己当初所配置的环境，所以没必要初始化，只需要安装相关依赖，然后渲染自己的博客源文件<code>hexo g</code>,并在本地新开一个端口做测试<code>hexo s -p 5000</code>, 你会发现本地展示效果和通过username.github.io一致。至此已搞定全部问题。</p><p>需要注意的是，我这里是在本地做的测试。如果换台机器，保证已安装有git和node.js的前提下，按照上述再操作一遍即可。</p>]]></content>
      
      
        <tags>
            
            <tag> GitHub Pages </tag>
            
            <tag> Hexo </tag>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
