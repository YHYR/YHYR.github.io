<!DOCTYPE html PUBLIC "-//WAPFORUM//DTD XHTML Mobile 1.0//EN" "http://www.wapforum.org/DTD/xhtml-mobile10.dtd">
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=yes">
  
  
  <title>  Kafka实践之Consumer |   【永恒依然】的博客 </title>

 
  
    <link rel="icon" href="/images/favicon.png">
  


  <link rel="stylesheet" href="/nayo.min.css"> 
</head>  
  <body>   
    
      <header class="header">
	
  <nav class="header-nav">        
   
    <span class="iconfont icon-menu mobile-toggle"></span>   	

    <!-- <a class="header-logo" href="/"></a> -->

    <div class="header-menu">          
              
            

              <a class="header-menu-link" id="header-menu-home" href="/">Home</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-archives" href="/archives">Archives</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-tags" href="/tags">Tags</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-about" href="/about">About</a>     

            
            
            

              <a class="iconfont icon-menu-search header-menu-link" id="header-menu-search"></a>

            
                
    </div>  
    
  </nav>
</header>   

      <div class="container">       
          
          
            <section class="main">  
          

          <article class="post">
  
	<div class="post-header">

	<p class="post-title">	
		Kafka实践之Consumer
	</p>
			

	<div class="meta-info">	
	<span>
		Jan 01, 2019
	</span>

	
	
		<i class="iconfont icon-words"></i>
		<span>
			10563
		</span>
	
</div>

</div> 
	 

	  <div class="post-content slideDownMin">

		

			
					<p>从几个应用案例出发，加深对Kafka Consumer的使用。</p>
<a id="more"></a>
<p>本文设计的所有代码详见<a href="https://github.com/YHYR/Kafka-Utils" target="_blank" rel="noopener">Github</a></p>
<p>上手Kafka Consumer是比较容易的，这里以原生的Java API为例，通常的实现逻辑如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String brokers = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    String group = <span class="string">"group_test"</span>;</span><br><span class="line">    String topic = <span class="string">"topic_demo"</span>;</span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, brokers);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, group);</span><br><span class="line">    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">    props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">    consumer.subscribe(Collections.singletonList(topic));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">            System.out.println(record.toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对应的maven依赖为</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到通过配置一些参数，并调用poll方法就可以开始消费消息。如果想要了解Consumer的实现原理，当然绕不开阅读poll方法的源码，本篇先抛开poll的实现原理，可以先简单的理解为：调用poll方法可以实现将Client加入到Group中，获取Partition信息，并且拉去对应Partition上的数据。接下来首先会对Consumer的几个主要的参数做以说明，然后通过几个案例来加深对Consumer的使用。在案例的实现过程中涉及到有过Kafka底层的相关知识，若有不清楚的可先阅读<a href="https://yhyr.github.io/2018/12/15/Kafka%E7%90%86%E8%AE%BA%E4%B9%8BPartition-Replication/" target="_blank" rel="noopener">Partition &amp; Replication</a>、<a href="https://yhyr.github.io/2018/12/26/Kafka%E7%90%86%E8%AE%BA%E4%B9%8BConsumer-Group-Coordinator/" target="_blank" rel="noopener">Consumer-Group-Coordinator</a> 。</p>
<p><em>poll()源码的分析可参考<a href="https://matt33.com/2017/11/11/consumer-pollonce/" target="_blank" rel="noopener">poll模型</a> </em></p>
<h1 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h1><h2 id="client-id"><a href="#client-id" class="headerlink" title="client.id"></a>client.id</h2><p>用来指定当前客户端的标识符名称，不同的客户端API会有与之对应的命名规则；例如原生的Java API中client.id的命名规则是以“consumer-”为前缀，后跟自增长Id；在Kafka-Python中，client.id的命名规则为“kafka-python-” + Kafka-Python版本号。通常是不需要业务代码里显示的指定，但是在特定场景下，可以根据client.id来改变Partition的分配结果，从而实现特殊的需求。</p>
<h2 id="session-timeout-ms"><a href="#session-timeout-ms" class="headerlink" title="session.timeout.ms"></a>session.timeout.ms</h2><p>在无心跳时，broker判定Consumer Client存活的最大时间间隔；即就是在此时间范围内，如果客户端不发送心跳，Coordinator也会认为该Client依旧是存活的；一旦超过该时间Coordinator仍未收到心跳，则会判定该Client已经dead，并主动触发Rebalance；默认时长为3000(3s)。</p>
<p>在实际应用中，必须斟酌在真实业务场景中消息处理的实际耗时与session.timeout.ms的大小，否则会出现因为处理超时导致在offset还未提交时Coordinator主动触发了Group的Rebalance，从而造成消息重复消费的情况。</p>
<h2 id="heartbeat-interval-ms"><a href="#heartbeat-interval-ms" class="headerlink" title="heartbeat.interval.ms"></a>heartbeat.interval.ms</h2><p>Consumer Client向Coordinator发送心跳的频率；默认为session.timeout.ms的三分之一</p>
<h2 id="auto-offset-reset"><a href="#auto-offset-reset" class="headerlink" title="auto.offset.reset"></a>auto.offset.reset</h2><p>控制Consumer读取Offset的方式，可选项为latest(default)或earlist；适用场景：</p>
<blockquote>
<p>1, 当没有Offset提交记录时(可以理解为加入新的Group)</p>
<p>2, 已存在的Offset失效</p>
</blockquote>
<p>对于该参数的使用，通常都只关注了场景1的使用，对于场景2的情况，在特定情况下也是非常有用的，具体可详见下文中有关不停服而修改offset位置案例。</p>
<h2 id="max-poll-records"><a href="#max-poll-records" class="headerlink" title="max.poll.records"></a>max.poll.records</h2><p>指定每调用一次poll方法所能拉取到的数据量；这里所指的数据量是消息的条数，即就是执行一次poll方法，返回的ConsumerRecords的size；默认大小为500；最大拉取量是基于当前客户端所有被分配的Partition而言，而不是每个Partition各五百条。</p>
<h1 id="Offset-Option"><a href="#Offset-Option" class="headerlink" title="Offset Option"></a>Offset Option</h1><h2 id="Consumer-Special-Offset"><a href="#Consumer-Special-Offset" class="headerlink" title="Consumer Special Offset"></a>Consumer Special Offset</h2><p>在数据监控中普遍存在这样一种场景：查找出某一天或者某几天内的消息用来进行数据验证或者数据嗅探。基于这种需求来讨论一下如果实现：“从2018-12-31当天产生的第一条消息开始，重新消费Topic(topic_demo)”。</p>
<p>首先获取2018-12-31(1546185600000)当天记录的第一条消息的offset值</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list  localhost:9092 --topic &lt;string&gt; --time 1546185600000</span><br></pre></td></tr></table></figure>
<p>为了方便举例，假设Topic只有一个分区。则通过执行如上命令可以得到topic对应的分区0在2018年12月31号这天所记录的第一条消息的offset值(还可以通过代码实现获取offset值，详见<a href="https://github.com/YHYR/Kafka-Utils/blob/master/Kafka-Utils-Java/src/main/java/com/yhyr/comsumer/GetOffsetWithTimestamp.java" target="_blank" rel="noopener">Java版</a>、<a href="https://github.com/YHYR/Kafka-Utils/blob/master/Kafka-Utils-Python/consumer/get_offset_with_timestamp.py" target="_blank" rel="noopener">Python版</a>)；假设该值等于500，则基于指定Offset进行消费的代码(Java)如下所示</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumerSpecialOffset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  String brokers = <span class="string">"localhost:9092"</span>;</span><br><span class="line">  String topic = <span class="string">"topic_demo"</span>;</span><br><span class="line">  String group = <span class="string">"group_test"</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 自定义消费的位置</span></span><br><span class="line">  <span class="keyword">int</span> customPartitionOffset = <span class="number">500</span>;</span><br><span class="line"></span><br><span class="line">  Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">  props.put(<span class="string">"bootstrap.servers"</span>, brokers);</span><br><span class="line">  props.put(<span class="string">"group.id"</span>, group);</span><br><span class="line">  props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"false"</span>); <span class="comment">// 不提交Offset</span></span><br><span class="line">  props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>);</span><br><span class="line">  props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">  props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">  KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * KafkaConsumer.seek 是基于客户端的行为;</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 因此在订阅Topic后, 必须调用一次poll方法, 用来加入指定Group并获取Client被分配的Partition, 方可通过seek重新指定消费位置</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">  consumer.subscribe(Collections.singletonList(topic));</span><br><span class="line">  consumer.poll(<span class="number">0</span>);</span><br><span class="line">  consumer.assignment().forEach(topicPartition -&gt; consumer.seek(topicPartition, customPartitionOffset));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">      System.out.println(record.toString());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为这里只是数据的嗅探测试，并不想改变Broker端存储的Offset信息，所以这里指定enable.auto.commit为false；只消费不提交；当然如果是在生产环境中，为了尽可能的避免或者减少对线上服务的印象，可以优先考虑指定一个新的Group，这样就可以避免因为新增Consumer而导致的Rebalance操作。通过KafkaConsumer.seek()方法来改变和指定当前Consumer的Offset位置，这种操作不会影响到其他Client，且仅对本次有效。</p>
<p>如果要想实现获取指定时间窗的消息，其实也简单；实现的方法也很多，这里简单介绍两种</p>
<p>方法一：通过Offset来获取时间窗内的数据</p>
<p>分别获取时间窗前后的Offset临界值，然后通过对ConsumerRecord中的Offset值进行判断从而筛选数据</p>
<p>方法二：通过时间戳来获取指定时间窗内的数据</p>
<p>直接通过对比ConsumerRecord中的timestamp和目标时间窗来实现数据的筛选</p>
<h2 id="Commit-Special-Offset"><a href="#Commit-Special-Offset" class="headerlink" title="Commit Special Offset"></a>Commit Special Offset</h2><p><strong>在不触发Rebalance的前提下</strong>修改Broker端存储的Offset值</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commitSpecialOffset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String brokers = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    String group = <span class="string">"group_test"</span>;</span><br><span class="line">    String topic = <span class="string">"topic_demo"</span>;</span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, brokers);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, group);</span><br><span class="line">    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">    props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取Topic的Partition信息</span></span><br><span class="line">    List&lt;PartitionInfo&gt; partitionInfos = consumer.partitionsFor(topic);</span><br><span class="line">    <span class="comment">// 将所有Partition的offset设置为10</span></span><br><span class="line">    <span class="keyword">int</span> resetOffsetValue = <span class="number">10</span>;</span><br><span class="line">    partitionInfos.forEach(partitionInfo -&gt; currentOffsets.put(<span class="keyword">new</span> TopicPartition(partitionInfo.topic(),</span><br><span class="line">        partitionInfo.partition()), <span class="keyword">new</span> OffsetAndMetadata(resetOffsetValue)));</span><br><span class="line">    consumer.commitSync(currentOffsets);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述例子的应用场景比较局限，仅限于指定Group下Partition未被其他Client所占用的时候才可以修改；但是在实际的应用场景中，很有可能存在这种场景：因为脏数据需要修改Offset的位置，但是又不能停止服务。</p>
<p>例如Group(group_test)下的Topic(topic_demo)只有一个Partition，正在被服务A所占用；分区topic_demo-0的有效offset范围为100 ~ 1000；且从500处开始一直到1000，所有的消息均是脏数据，现在需要在不停服的前提下，将Offset的位置改变成最新状态。</p>
<p>要实现<font color="red">不停服更新Offset</font>，就需要了解Consumer Rebalance和Partition Assignment；这里简单阐述一下(有关Rebalance的相关知识、分区分区策略的原理详见<a href="https://yhyr.github.io/2018/12/26/Kafka%E7%90%86%E8%AE%BA%E4%B9%8BConsumer-Group-Coordinator/" target="_blank" rel="noopener">Consumer-Group-Coordinator</a> )：</p>
<p>Rebalance：Rebalance是基于Group而言的，一个Group中Consumer个数的变化会触发Rebalance；Group在Rebalance期间对外表现为不可用；没经过一次Rebalance，都会按照客户端的分区分配策略来分发客户端将要处理的Partition。</p>
<p>分区分配策略：Kafka的分区分配策略是用Consumer来决定的，默认的分区分配原则为RangeAssignor，即就是对于每个被订阅的Topic，尽可能将连续的Partition分给同一个Consumer Client。分配算法如下所示：</p>
<ul>
<li>1，将Consumer Client按照命名排序</li>
<li>2，计算平均每个Consumer可以分到的Partition个数 =&gt; n / m</li>
<li>3，计算平均分配后剩余的Partition个数 =&gt; n % m</li>
<li>4，如果n%m等于零，则代表所有客户端可以一次平均分配到n/m个Partition；如果n%m大于零，则前n%m个Consumer分配到(n / m + 1)个Partition，剩下的Consumer(m - n % m)分配(n / m)个Partition</li>
</ul>
<p>结合上述两点就可以很容易实现不停服更新Offset的需求：即就是只要保证我的Offset更新服务B的client.id在排序上位于服务A的client.id，这样就可以保证在Rebalance之后一定能分配到该Partition，从而来执行Offset的更新操作(Offset的更新可以分为两种：直接将Offset指定为最大值；或者将Offset设定为一个无效值；这里采用第二种方案，因为Partition的有效Offset范围为100 ~ 1000，所以将Offset设置为10，则会因为auto.offset.reset=true的配置自动将Offset重新设置为latest)；当更新完成并安全退出后，再次触发Rebalance，此时Group中只剩下服务A，当服务A再次获取到当前Partition时，根据服务A的配置 <code>auto.offset.reset=true</code>，就可以保证此时的Offset为最新位置。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String brokers = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    String group = <span class="string">"group_test"</span>;</span><br><span class="line">    String topic = <span class="string">"topic_demo"</span>;</span><br><span class="line"></span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    <span class="comment">// 指定client.id的值, 保证在排序时在首位</span></span><br><span class="line">    String clientId = <span class="string">"aaa"</span>;</span><br><span class="line">    props.put(<span class="string">"client.id"</span>, clientId);</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, brokers);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, group);</span><br><span class="line">    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">    props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 触发Rebalance</span></span><br><span class="line">    consumer.subscribe(Collections.singletonList(topic));</span><br><span class="line">    consumer.poll(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取Topic的Partition信息</span></span><br><span class="line">    List&lt;PartitionInfo&gt; partitionInfos = consumer.partitionsFor(topic);</span><br><span class="line">    <span class="comment">// 将所有Partition的offset设置为10</span></span><br><span class="line">    <span class="keyword">int</span> resetOffsetValue = <span class="number">10</span>;</span><br><span class="line">    partitionInfos.forEach(partitionInfo -&gt; currentOffsets</span><br><span class="line">        .put(<span class="keyword">new</span> TopicPartition(partitionInfo.topic(), partitionInfo.partition()),</span><br><span class="line">            <span class="keyword">new</span> OffsetAndMetadata(resetOffsetValue)));</span><br><span class="line">    consumer.commitSync(currentOffsets);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为由Rebalance造成的服务不可用时间通常都比较短，且远小于停服重启所带来的影响；假设由Rebalance造成的不可用时长是可以接受的，这样就可以基于上述方案实现Offset的修改。</p>
<h1 id="Consumer-Rebalance-Listener"><a href="#Consumer-Rebalance-Listener" class="headerlink" title="Consumer Rebalance Listener"></a>Consumer Rebalance Listener</h1><p>Rebalance的设计很好的提升了Kafka的容错率和可扩展性；但并非所有的Rebalance都是我们期望的。在介绍Consumer参数时有说到一个参数session.timeout.ms，在session.timeout.ms内没有发送心跳就会触发Rebalance。在实际应用中，造成心跳未按时发送的原因很多，网络、消息处理延迟等等，并不是所有的未发送我们都期望进行Rebalance，那么该如何消除这种情况呢？增大session.timeout.ms的时间区间是一个很直接办法，但并不是一个有效的办法，因为时间区间的界定是个难度比较大的问题。太小还是容易触发Rebalance，但是太大肯定是不合理。所以在这里介绍一种：通过客户端监听Rebalance行为来自定义控制Offset、告警，从而解决非正常Rebalance导致的消息重复问题，也可以快速感知到问题的发生。</p>
<p>例如有如下场景，当一次性拉取多条数据，且在数据处理未完全处理完时，发生Rebalance导致新分配的Client基于从原始的消息位置开始消费，从而导致数据的重复消费问题</p>
<p><img src="./offset-消息重复.png" alt="offset-消息重复"></p>
<p><em>图片来自Kafka权威指南 Chapter 4/Commits and Offset</em></p>
<p>要解决该问题，可以通过监听Consumer的Rebalance行为，在发生前将该处理的操作及时的处理完，样例代码如下所示，每次Rebalance前打印当前的Offset信息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String brokers = <span class="string">"localhost:9092"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String group = <span class="string">"group_test"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String topic = <span class="string">"topic_demo"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> KafkaConsumer&lt;String, String&gt; consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, brokers);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, group);</span><br><span class="line">    props.put(<span class="string">"enable.auto.commit"</span>, <span class="string">"true"</span>);</span><br><span class="line">    props.put(<span class="string">"auto.commit.interval.ms"</span>, <span class="string">"1000"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomHandleRebalance</span> <span class="keyword">implements</span> <span class="title">ConsumerRebalanceListener</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; collection)</span> </span>&#123;</span><br><span class="line">        System.out.println(String.format(</span><br><span class="line">            <span class="string">"Before Rebalance, Assignment partitions is: %s; Current each partition's latest offset is: %s"</span>,</span><br><span class="line">            collection.toString(), currentOffsets.toString()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; collection)</span> </span>&#123;</span><br><span class="line">        System.out.println(String.format(</span><br><span class="line">            <span class="string">"After Rebalance, Assignment partitions is: %s; Current each partition's latest offset is: %s"</span>,</span><br><span class="line">            collection.toString(), currentOffsets.toString()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        consumer.subscribe(Collections.singletonList(topic), <span class="keyword">new</span> CustomHandleRebalance());</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                <span class="comment">// record current msg's offset</span></span><br><span class="line">                currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), <span class="keyword">new</span> OffsetAndMetadata(</span><br><span class="line">                    record.offset()));</span><br><span class="line">                <span class="comment">// processing msg</span></span><br><span class="line">                System.out.println(<span class="string">"Processing msg : "</span> + record.toString());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        System.out.println(<span class="string">"Unexpected error: "</span> + e.getMessage());</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        consumer.commitSync(currentOffsets);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  	
					
	  </div>     
	  

	
<div class="post-meta">
      	

      
        <i class="iconfont icon-tag"></i>     
          <a class="tag-link" href="/tags/Kafka/">Kafka</a>    
      	
</div>





<div class="post-footer">
  <div class="pf-left">
      <img class="pf-avatar" src="/images/header.jpg">
      <p class="pf-des">YHYR</p>
  </div>

  <div class="pf-right">           
      <div class="pf-links">
        




<span class="donate-btn">
	<span class="iconfont icon-donate"></span>
</span>


<div id="donate-box" class="sildeUpMin">

	<span class="donate-cancel iconfont icon-cancel"></span>

	<div class="donate-img-box">
		<img id="donate-qr-wechat" class="noLazyLoad donate-img" src="/images/donate_wechat.png" alt="No Donate Image!">	
		<img id="donate-qr-alipay" class="noLazyLoad donate-img" src="/images/donate_wechat.png" alt="No Donate Image!">	
	</div>

	<span class="donate-word">您的认可是我坚持下去的理由</span>

	<div class="donate-list">
		<span class="iconfont icon-donate-wechat"></span>
		<span class="iconfont icon-donate-alipay"></span>
	</div>

</div>

 
        
	
<script id="-mob-share" src="http://f1.webshare.mob.com/code/mob-share.js?appkey=21d601593a1de"></script>
	
	<span class="share-btn">
	<span class="iconfont icon-share"></span>
	</span>


	<div class="-mob-share sildeUpMin">
		   			             
            <a class="iconfont  icon-share-qq -mob-share-qq"></a>		
     	   			             
            <a class="iconfont  icon-share-weixin -mob-share-weixin"></a>		
     	   			             
            <a class="iconfont  icon-share-weibo -mob-share-weibo"></a>		
     	   			             
            <a class="iconfont  icon-share-douban -mob-share-douban"></a>		
     	   			             
            <a class="iconfont  icon-share-facebook -mob-share-facebook"></a>		
     	   			             
            <a class="iconfont  icon-share-twitter -mob-share-twitter"></a>		
     	   			             
            <a class="iconfont  icon-share-google -mob-share-google"></a>		
     	   
	</div>	

      </div>  
    <nav class="pf-paginator">
           
        
      
        
        <a href="/2019/01/01/Kafka实践之常用命令/" data-hover="Kafka实践之常用命令"> Next</a>
            
  </nav>   
  </div>
</div> 
	


    
    <div id="disqus_thread"></div>

    <script>
    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://'+'lemonreds'+'.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());    
    (d.head || d.body).appendChild(s);
    })();
    </script>

    <noscript>Please enable JavaScript to view the  <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>


	
</article>

          </section> 
      </div>            
    
    <a id="backTop">
      <span>
        <i class="iconfont icon-backtotop"></i>
      </span>
    </a> 

  
    

        
        <div class="search-container sildeUpMin">


            <div class="search-header">
            <input type="text" placeholder="Typing Something here." id="search-input" class="search-input">  
            <span class="search-cancel iconfont icon-cancel"></span>
          
            </div>
              
            <div id="search-result" class="search-result"></div>

        </div>
 

     <div class="mobile-menu">      

      
      <img class="mobile-menu-icon" src="/images/favicon.png">   
      

         
            

            <a class="mobile-menu-link" href="/">Home
            </a>
            
         
            

            <a class="mobile-menu-link" href="/archives">Archives
            </a>
            
         
            

            <a class="mobile-menu-link" href="/tags">Tags
            </a>
            
         
            

            <a class="mobile-menu-link" href="/about">About
            </a>
            
         
                          

            <a class="mobile-menu-link mobile-menu-search" href="#">Search </a>                 
            
         
      
</div>        
    


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?636802045446222199ae541e32c8133e"; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>





     
    




<footer id="footer">	    

		
		<div class="footer-copyright">
		&copy;
				
		2018-
		
		2019		
		
		YHYR
		<br>
		<!-- annotate theme msg in footer  by yhyr 2018/06/02
		Theme By
		<a href="https://github.com/Lemonreds/hexo-theme-Nayo" target="_blank">Nayo</a>	
		-->
		</div>			
	 
</footer>   

  

    <script src="/nayo.bundle.js"></script>           
  </body>        
</html>